{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oBj92YlIeXTh",
        "outputId": "5938bb6b-93f6-456f-af60-16a69f9b58e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.23-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.16-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchainhub\n",
            "  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.8-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.4.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting tavily-python\n",
            "  Downloading tavily_python-0.7.2-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.56 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.56)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.39)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Collecting langchain-core<1.0.0,>=0.3.56 (from langchain_community)\n",
            "  Downloading langchain_core-0.3.58-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.76.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchainhub) (24.2)\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
            "  Downloading types_requests-2.32.0.20250328-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.4)\n",
            "Collecting fastapi==0.115.9 (from chromadb)\n",
            "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-4.0.1-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.3)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.25-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt>=0.1.8 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.66-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.24.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.56->langchain_community) (1.33)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
            "  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (75.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.30.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.56->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading langchain_community-0.3.23-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.16-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
            "Downloading chromadb-1.0.8-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.9/18.9 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.4.1-py3-none-any.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.2/151.2 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tavily_python-0.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.58-py3-none-any.whl (437 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.6/437.6 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.25-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_sdk-0.1.66-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl (188 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.32.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.53b1-py3-none-any.whl (7.3 kB)\n",
            "Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-4.0.1-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20250328-py3-none-any.whl (20 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53801 sha256=3d36de2b31e0cbaf9cfe86de88c69c62f613ac0658a45bbe6801977c7a295ece\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, xxhash, uvloop, uvicorn, types-requests, python-dotenv, overrides, ormsgpack, opentelemetry-util-http, opentelemetry-proto, mypy-extensions, mmh3, marshmallow, importlib-metadata, humanfriendly, httpx-sse, httptools, bcrypt, backoff, asgiref, watchfiles, typing-inspect, tiktoken, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, langchainhub, coloredlogs, tavily-python, pydantic-settings, opentelemetry-semantic-conventions, onnxruntime, langgraph-sdk, kubernetes, fastapi, dataclasses-json, opentelemetry-sdk, opentelemetry-instrumentation, langchain-core, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langgraph-checkpoint, langchain-openai, opentelemetry-instrumentation-fastapi, langgraph-prebuilt, langgraph, langchain_community, chromadb\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.7.0\n",
            "    Uninstalling importlib_metadata-8.7.0:\n",
            "      Successfully uninstalled importlib_metadata-8.7.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.16.0\n",
            "    Uninstalling opentelemetry-api-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.16.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.16.0\n",
            "    Uninstalling opentelemetry-sdk-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.16.0\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.56\n",
            "    Uninstalling langchain-core-0.3.56:\n",
            "      Successfully uninstalled langchain-core-0.3.56\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.8 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.9 fastapi-0.115.9 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 importlib-metadata-8.6.1 kubernetes-32.0.1 langchain-core-0.3.58 langchain-openai-0.3.16 langchain_community-0.3.23 langchainhub-0.1.21 langgraph-0.4.1 langgraph-checkpoint-2.0.25 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.66 marshmallow-3.26.1 mmh3-5.1.0 mypy-extensions-1.1.0 onnxruntime-1.21.1 opentelemetry-api-1.32.1 opentelemetry-exporter-otlp-proto-common-1.32.1 opentelemetry-exporter-otlp-proto-grpc-1.32.1 opentelemetry-instrumentation-0.53b1 opentelemetry-instrumentation-asgi-0.53b1 opentelemetry-instrumentation-fastapi-0.53b1 opentelemetry-proto-1.32.1 opentelemetry-sdk-1.32.1 opentelemetry-semantic-conventions-0.53b1 opentelemetry-util-http-0.53b1 ormsgpack-1.9.1 overrides-7.7.0 posthog-4.0.1 pydantic-settings-2.9.1 pypika-0.48.9 python-dotenv-1.1.0 starlette-0.45.3 tavily-python-0.7.2 tiktoken-0.9.0 types-requests-2.32.0.20250328 typing-inspect-0.9.0 uvicorn-0.34.2 uvloop-0.21.0 watchfiles-1.0.5 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "ec648ce507924680826128d8840a1e63"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "! pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain langgraph tavily-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "\n",
        "def _set_env(key: str):\n",
        "    if key not in os.environ:\n",
        "        os.environ[key] = getpass.getpass(f\"{key}:\")\n",
        "\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")\n",
        "_set_env(\"TAVILY_API_KEY\")"
      ],
      "metadata": {
        "id": "s-n8zveyeZzj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11140425-5d12-4644-9212-e65dd6eb56b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY:··········\n",
            "TAVILY_API_KEY:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Index"
      ],
      "metadata": {
        "id": "CwdfDRC6ewol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "urls = [\n",
        "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
        "]\n",
        "\n",
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "# print(\"DOCS\")\n",
        "# print(docs)\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "# print(\"List\")\n",
        "# print(docs)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=250, chunk_overlap=0\n",
        ")\n",
        "doc_splits = text_splitter.split_documents(docs_list)\n",
        "\n",
        "# Add to vectorDB\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=doc_splits,\n",
        "    collection_name=\"rag-chroma\",\n",
        "    embedding=OpenAIEmbeddings(),\n",
        ")\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "Mc_PmVbyehE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf8714e-f2cc-4a0c-d3e0-4187a277277e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLMs"
      ],
      "metadata": {
        "id": "zLx9VuVXsEHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Retrieval Grader\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "# Data model\n",
        "class GradeDocuments(BaseModel):\n",
        "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "\n",
        "# LLM with function call\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
        "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You are a grader judging relevance of a retrieved document to a user question. \\n\n",
        "    If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. \\n\n",
        "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
        "grade_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "retrieval_grader = grade_prompt | structured_llm_grader\n",
        "question = \"agent memory\"\n",
        "docs = retriever.get_relevant_documents(question)\n",
        "doc_txt = docs[1].page_content\n",
        "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyIzLvVYsCue",
        "outputId": "222ea95a-d74f-4afc-e2e7-df26ced70d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1630: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1643: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo-0125 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-5b23c10c6e05>:34: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  docs = retriever.get_relevant_documents(question)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "binary_score='yes'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Generate\n",
        "\n",
        "from langchain import hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Prompt\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "# LLM\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "\n",
        "# Post-processing\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "# Chain\n",
        "rag_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "# Run\n",
        "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
        "print(generation)"
      ],
      "metadata": {
        "id": "lsi0QyXWgFIr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac4abd38-44fb-40a9-f3fa-119a6d7268ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent memory consists of short-term memory for in-context learning and long-term memory for retaining and recalling information over extended periods. Long-term memory is often supported by an external vector store for fast retrieval. Agents can utilize external APIs to access additional information beyond their pre-training model weights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Question Re-writer\n",
        "\n",
        "# LLM\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n\n",
        "     for web search. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
        "re_write_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
        "question_rewriter.invoke({\"question\": question})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sZooKNq6_uwj",
        "outputId": "6a9b71eb-b5b3-42db-bb5c-4f0e303b6682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is the role of memory in artificial intelligence agents?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web Search Tool"
      ],
      "metadata": {
        "id": "JvWYttJD_1Wd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Search\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "web_search_tool = TavilySearchResults(k=3)"
      ],
      "metadata": {
        "id": "7YhF6K2q_zp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Graph State\n",
        "\n",
        "from typing import List\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        question: question\n",
        "        generation: LLM generation\n",
        "        web_search: whether to add search\n",
        "        documents: list of documents\n",
        "    \"\"\"\n",
        "\n",
        "    question: str\n",
        "    generation: str\n",
        "    web_search: str\n",
        "    documents: List[str]\n"
      ],
      "metadata": {
        "id": "AlzCOLAp_3mG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import Document\n",
        "\n",
        "\n",
        "def retrieve(state):\n",
        "    \"\"\"\n",
        "    Retrieve documents\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, documents, that contains retrieved documents\n",
        "    \"\"\"\n",
        "    print(\"---RETRIEVE---\")\n",
        "    question = state[\"question\"]\n",
        "\n",
        "    # Retrieval\n",
        "    documents = retriever.get_relevant_documents(question)\n",
        "    return {\"documents\": documents, \"question\": question}\n",
        "\n",
        "\n",
        "def generate(state):\n",
        "    \"\"\"\n",
        "    Generate answer\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, generation, that contains LLM generation\n",
        "    \"\"\"\n",
        "    print(\"---GENERATE---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # RAG generation\n",
        "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
        "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
        "\n",
        "\n",
        "def grade_documents(state):\n",
        "    \"\"\"\n",
        "    Determines whether the retrieved documents are relevant to the question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with only filtered relevant documents\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # Score each doc\n",
        "    filtered_docs = []\n",
        "    web_search = \"No\"\n",
        "    for d in documents:\n",
        "        score = retrieval_grader.invoke(\n",
        "            {\"question\": question, \"document\": d.page_content}\n",
        "        )\n",
        "        grade = score.binary_score\n",
        "        if grade == \"yes\":\n",
        "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
        "            filtered_docs.append(d)\n",
        "        else:\n",
        "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
        "            web_search = \"Yes\"\n",
        "            continue\n",
        "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
        "\n",
        "\n",
        "def transform_query(state):\n",
        "    \"\"\"\n",
        "    Transform the query to produce a better question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates question key with a re-phrased question\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---TRANSFORM QUERY---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # Re-write question\n",
        "    better_question = question_rewriter.invoke({\"question\": question})\n",
        "    return {\"documents\": documents, \"question\": better_question}\n",
        "\n",
        "\n",
        "def web_search(state):\n",
        "    \"\"\"\n",
        "    Web search based on the re-phrased question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with appended web results\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---WEB SEARCH---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # Web search\n",
        "    docs = web_search_tool.invoke({\"query\": question})\n",
        "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
        "    web_results = Document(page_content=web_results)\n",
        "    documents.append(web_results)\n",
        "\n",
        "    return {\"documents\": documents, \"question\": question}\n",
        "\n",
        "\n",
        "### Edges\n",
        "\n",
        "\n",
        "def decide_to_generate(state):\n",
        "    \"\"\"\n",
        "    Determines whether to generate an answer, or re-generate a question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Binary decision for next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
        "    state[\"question\"]\n",
        "    web_search = state[\"web_search\"]\n",
        "    state[\"documents\"]\n",
        "\n",
        "    if web_search == \"Yes\":\n",
        "        # All documents have been filtered check_relevance\n",
        "        # We will re-generate a new query\n",
        "        print(\n",
        "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
        "        )\n",
        "        return \"transform_query\"\n",
        "    else:\n",
        "        # We have relevant documents, so generate answer\n",
        "        print(\"---DECISION: GENERATE---\")\n",
        "        return \"generate\""
      ],
      "metadata": {
        "id": "ZAQV4kB4ADPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()"
      ],
      "metadata": {
        "id": "UEV1wAQ6pUq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile Graph\n",
        "# The just follows the flow we outlined in the figure above.\n",
        "\n",
        "\n",
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Define the nodes\n",
        "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
        "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
        "workflow.add_node(\"generate\", generate)  # generate\n",
        "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
        "workflow.add_node(\"web_search_node\", web_search)  # web search\n",
        "\n",
        "# Build graph\n",
        "workflow.add_edge(START, \"retrieve\")\n",
        "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"grade_documents\",\n",
        "    decide_to_generate,\n",
        "    {\n",
        "        \"transform_query\": \"transform_query\",\n",
        "        \"generate\": \"generate\",\n",
        "    },\n",
        ")\n",
        "workflow.add_edge(\"transform_query\", \"web_search_node\")\n",
        "workflow.add_edge(\"web_search_node\", \"generate\")\n",
        "workflow.add_edge(\"generate\", END)\n",
        "\n",
        "# Compile\n",
        "app = workflow.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "DOjkZbCzAD7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(app.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "MYYhqS3JL4xC",
        "outputId": "62e7f0f9-df9e-49f4-8de5-68226c7c4716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOkAAAJ2CAIAAAA1+jILAAAQAElEQVR4nOydB1gUVxeG73bYXXpHehcRsPdgx8SW3xY7GpVExWjs2GuMNdZYY4s9SkzUxBKNvcWCigUpNqp02KVt4T8wyYYkiKAsu3f3vM8++8zMnbkzs/vNme+embnDLSkpIQhCIVyCIHSC2kVoBbWL0ApqF6EV1C5CK6hdhFbo0G52miwvUybNVeTnKWRFSkIDPAFLaMQVGXOMzXkmVjyC1DQsbc7vpjwrjHsgef5QambLlxUqRcZcsRmPQ8mpQi4rkWbLpblyngEnK6XIpZ7Ivb6RrauAIDWElmo3PbHo6rEMsSnX1JrnWk9sZkN33MpKlT17KMl+LZPkyFt2t7S05xPkvdFG7V7+KT3haT78x04+QqJbvHicf/VYupOPqFUPC4K8H1qm3RKyd+mLlt2sXP10TbXliX8gvfFrxoCpTgR5D9hEa1AqyfqJsR8Nt9Nt4QJu9UWdh9iu/zK2hI5mp5aiLXFXqSCbpsaOWelB9IeS0mM1bJUHYRHkHdCWuLtv6YsB05yJXsEiA6c57Vv2kiDvhFbE3Us/pjt6C118ddwqVMizh9LE2ILWPS0JUk00H3eTnxWmvizUT+ECrvVESfEFqS+LCFJNNK/dq8fTIR1G9JiW3SwhcUaQaqJh7b6KzreyF9i7GRA9xsHT0MyanxBTQJDqoGHtxtyVWNap7cukHTt2TEpKItXk4MGD8+bNI+rBsg4/5m4eQaqDhrUbHyV19RORWiQxMTE7O5tUn0ePHhG14eonhkYbQaqDJvMMKc+L7l3MCh5qS9SATCZbu3btuXPnMjMzzczMOnfuHBYWdvv27bFjxzIzBAUFrVy5MiMjY/Xq1X/88Udubq6trW3//v379esHpTExMQMGDPjmm2/WrFkjFAp5PN69e/eYBffu3evt7U1qmpO7Uhq2N7N2xJt1qoomb8rKTivmcNSVl9+5c+epU6cWLlxYp06d58+fL1682MDAYOTIkUuWLAkPD9+zZ4+joyPMNnfu3OTk5GXLlpmbm9+9exfmBwV/8MEHIFYo3bp167Bhw+rWrWtjY/P55587OTlNnTrVyMiIqAE2h5X1uhi1W3U0qd38PLnQWF0bEBcX5+Xl1axZMxh2cHDYuHEjh8PhcrkiUalFMTY2ZgZAxzAd9MrMBjH1xo0boF2YCFMaNWrUrVs3pkJYls/nm5qaEvUgMubk5yoIUmU0qt1chdhUXRvQpk0biKkzZszo1KlTkyZNXFxcKpyNzWZDhAYvkZWVBfZJIpF4ePx9XdrPz4/UFiJjriRHTpAqo0ntstgsLk9djcWuXbuKxeLDhw/PnDlTqVR26NBhypQp/4qaxcXFoaGhhoaGEydOdHZ2hlgLA+VngBpIbcHlsQCCVBlNatdAyM7LlhG1EVRGYWHh5cuXly9fvmjRohUrVpSf4f79+2B2wdQ2aNCAmZKTk0M0RF6WHH4QglQZTf5YQiN1OTw4+58/f55J4kITDRK6PXr0ePr06b9mg7gL36pgHBkZmZKSQjSENEcuMsFHX6uBJrVrbM5nc4g6gJMvZBKgHQZGFhQM35Asa9iwISlrpcH3lStX4uPjoTEH+QS46JCenn716lVImTVv3hySEuB9/1snpBeiy3i39PBbYXNZxuao3WqgSe3W8TSIvpUnL1ZLgnnp0qWQN5g2bVqvXr2g0QYJB/C7MB0SXi1btgSZQl7M0tJyzpw5oOOePXvu2LFj/vz5AwcOTEhIGDNmzH8rhNTv69evR4wY8fjxY1LTFBcq4RKjvbshQaqMhu+BPLU7xc1P7Nmw9ppE2gkcwy+f5HcabEOQKqPhxoFnoNHrhEKi96QlFLkH6PsBXF00bLDc/EXXfkn3bWZsZlPxY9/gPuHKVoVFkJqF5FeFRX369IErwEQ9TJo0CQx0hUVw8blCrwzMmjULmowVFmUkF796mt/6Y7z9vHpo/rmJZw+lD6/ldhtpV2GpXC4Hl1lhUV5e3psuz8I1MxMTE6IeMjIyiooqvlUcpgsEFV/UBVlDIrnComNbkvzbmDrX1dO7798ZzTdsXeuJ4u5JU18W2ThV8K/DlVh7e3uiTVhY1GTXCinPC4VGXBTuO6AVyfCOA60j1iUoZHr39gBZUclPGxM7DLAmSPXRlgs5A6Y67V2qd0/Mlj4dPVXPno6uObSoX5wCifLwmleDwp3ZenBlVCEv2bvkRb+JTgYivA78jmjRD2coZncbab9xSmxGUjHRadISijdPj+/xeR0U7vugjX3pnd6TCmGpZTcLE0td67Y2J1125Vg6j8/uNAgvQ7wvWtqHaew9ydVjGZ4NxDaOBi5+ItpdBKShn0dJX78qionMa9nd0t2/Vh/R01W0uu9ouMQfczcPEsD1WpQma0XGHLEpj0tJLIYcgjRXLs1VsAiJupYDqUDPBkZwNBKkhtBq7ap4FZ2fnS7LL+uzv7iwhm+bfPmyNL/h5FTDPYryDdiQuBUac0ws+U7eeJNNzUOHdtXKli1b4Ds0NJQgVIE3jCK0gtpFaAW1i9AKahehFdQuQiuoXYRWULsIraB2EVpB7SK0gtpFaAW1i9AKahehFdQuQiuoXYRWULsIraB2EVpB7SK0gtpFaAW1i9AKahehFdQuQiuoXYRWULsIraB2CZ/Pf1Pf/4g2g9r98w2BCHWgdhFaQe0itILaRWgFtYvQCmoXoRXULkIrqF2EVlC7CK2gdhFaQe0itILaRWgFtYvQCmoXoRXULkIrqF2EVvT33YDdunXjcDiw+3l5efBtYmIC30ql8vjx4wShAf2Nu87OztevX2exWMyoRCKB7xYtWhCEEih/Qfp78Omnn5qampafYmRkFBISQhBK0F/tNmrUyNvbW2WZYMDPz69x48YEoQT91S4wfPhwsLnMsKWl5ciRIwlCD3qt3SZNmkCsZYZ9fX0DAgIIQg96rV1SFnrNzc0tLCyGDh1KEKrQujyDUk7Skopy0mUKeW30mWBA3Bt6di8dkLk/vplL1A+Hyza15FnaC9iYW38/tCu/+/hG7uObebJipZ2rYX6ebvb3ITTiJMXn8wVs32bGPk2NCPKuaJF2H13Pi7svbfuJLdEPfj+Q7NXQyKeJmCDvhLb4XVDt07sS/REu0K6/HbiUZ1FSgrwT2qLd+xdzWnSzInpG867W9y7mEOSd0ArtyopKUl8VCI31rvEiNuMmPytQyPT0lpL3RCu0m5cls7Q3IHqJZR1BToaMINVHW0JdUYGC6CVF+Yq/bgdCqgfmGBFaQe0itILaRWgFtYvQCmoXoRXULkIrqF2EVlC7CK2gdhFaQe0itILaRWhF359XmzVn0tRpYQShEL3Q7se9OianJFVY1KN7n17/608QCtF9z5CUnJiTk/2m0qZNsBMnWqE17s6eM3nBwvAdOzd92LX1tWuXYEpGRvrir2Z9MqBrl49ajQkbFhl5Gybeun1j0OCeMDBwUA+wBzDQo2e7iIgD08K/CP6wpUQiKe8Z5HL5tu82DB3WG4qGhPT66efDpKyfss5dWhw89L1q1TKZrHvPtrDqN60UqR1o1S6Px4t/FhsXH7Ps6/W+9fwVCsXU6WGPHkfNDF+0bct+H59608LHvXjxLDCg0ZzZS2D+zZv2hE9bAANcHu/YiQhPD+/Vq7YYGPzjhvf1G1Ycidg/dMionTsO9+s7GEZPnjomFoubNGlx6fLvqtlu374Bgm7fLvhNKyVIrUCrdtkcTmLiq2lT59WvH2hibHLz5tX4+NjJk2b5+zdwcHAKGzPJysom4scDXC5XKBSR0n7yjEWi0gEOh2MgMBg5Ymzdun5QqqowNy/3xC9HP+k3pGOHLna29t279ercqev+A7ugqF3bzg8f3ocQy8x54eJZD3cvZ2fXN62UILUCxW01R0dnI/Gf/Rs8iX4IkRiiLDPKZrMD/BvGxEZXuCCo9r8TY2OjwTM0afy3/YXaXr58XlRU1KplEEToK1cvkDJfcfXaxQ4dulR3pUiNQ3FbTST6u2cDiVQCNhR8qmoKnNCtrKzfuqCK/PzSZ80nTAxV9cjL9FyRmZUBYbh5s9aXL//eo3vvu5G3cnNzIBJXd6VIjaMjeQYIwBAaN2/cU34i+Iqq18AIetbMxa4u7uWnW1qUPnnftm2nRYtn5knyLl06By7Fxsa2RlaKvA86ol0f73qFhYUw4OTkwkyBhK65mUXVa/Dw8Ab7C9k0VQ3Z2VksNhtcAQxD3OXz+X/8ce3ipXPDh31eUytF3gcduTbRuHFzaD9BugqyVCCg386eDA0deOz4ESgyNjKG7xs3rjx/Hl9JDRBEoX22fcfG38+fgZQweINJU0YvX7GAKRUIBC1afLBv/w6pVNI2qONbV4rUAjoSdyFkLlu6fuPm1XPnTy0sLLC1tQ8JCe3TeyAUeXnVbdq05YZvV9b3C1y1clMllYwZPRHSEZu3rIGUgrm5BTTRRo74+3Jxh3bBM2Z92bx5axMT07euFKkFtKIvvcyU4l93pvQY7UT0j582vOg6ws7Mhk+QaoL3kSG0gtpFaAW1i9AKahehFdQuQiuoXYRWULsIraB2EVpB7SK0gtpFaAW1i9AKahehFdQuQitaoV0Oly0y0dOjSGzK4/LxUYt3QSvuPTex5L5+WVhcqJsvv66EonxFemKhkRlq913QlucmfJoaJ8bmEz0DdtmnqQlB3glt0e4H/7N8eDUr9UUh0RuSnxU8uZHTuic+3/aOaMVzEwxKRcmhbxKcfcWGYq65rQBGiS7CZpPM1OICifzlY0nfCY5s9AvvihZpl+Hh1dykZwXyYpKTUUxqBam0tGcGptecWsDUis/lEltXQ7+WxgR5D7ROu7XPli1b4Ds0NJQgVIH5XYRWULsIraB2EVpB7SK0gtpFaAW1i9AKahehFdQuQiuoXYRWULsIraB2EVpB7SK0gtpFaAW1i9AKahehFdQuQiuoXYRWULsIraB2EVpB7SK0gtpFaAW1i9AKahehFdQuEQqF2EkFjaB2SX6+3vXhpxugdhFaQe0itILaRWgFtYvQCmoXoRXULkIrqF2EVlC7CK2gdhFaQe0itILaRWgFtYvQCmoXoRXULkIrqF2EVvT33YDdunUrKYN5r6VYLIZhNpt9/PhxgtCA/sZde3v7O3fuqEYZBTdo0IAglKAt73GvfYYMGWJiYlJ+CowOHTqUIJSgv9pt06aNp6dn+SkeHh4wkSCUoL/aBfr3768KvTAwePBggtCDXmu3bdu2EGuZ1qq7uzsGXbrQa+0CAwcONDU1xaBLI2/PM0BUysuUSXMVRBfxcmrm69YKUmOejk2TnxUSXURoxDG24LFYRMd4S3731pmsB1dyuFyWQMQhCJ0USBQlypL6rUwadTQjOkRl2j1/OB1m8P/AjCfQd2tBO/LiksjzmVxuSZv/WRJd4Y3avRCRxuFyAoLMCaIrgHxLlMoPdEW+FQfU9MRiSZYChatjBLY1z8uUw59LdII3aDe5iM3ROW+PvgqmIAAAEABJREFUwHmWzcpIKSI6QcV5Bkm23NzOgCA6h4WdQJojJzpBxdpVyEpkMt1Miuk5xYVKnTmf4v27CK2gdhFaQe0itILaRWgFtYvQCmoXoRXULkIrqF2EVlC7CK2gdhFaQe0itKLVN5Wv+uarkaEDSM0xdFjvdRtWEEQnwAciKODjXh2TU5II8k/QM2g7ScmJOTnZBPkPNabdtLTXK1Ytunfvtlhs1K/v4NzcnMtXzu/c/gMU9ejZbljIZzf+uBoZeevID6cNDQ137d5y9uzJ9Iw0ExPT1q3aho76wsCg9Hbh9PS05SsXwmxQSY/ufcrXL5fLd+7afPHSudTUZGtr2z69B/bs0eetW/XgQeSadUtfvHhmZ1dn1Miw8kWpqSmbNq++fftGQWGBo6PzJ32HBAd3Y4oePXqwcfPqmJgnsHltgzqN+HQMn8/ft3/n93u2/XriMjMPBMKBg3p8vWRts6Ytj0Qc2LP3u5kzFm3c9E1SUkKdOo4zpi98/CQKFsnKyvD3bxg+bT5UBUtlZKTDSu8/uAtydHPzDB05LjCwEUyPj48dMar/iuXfHj6y7+HD+1wut127zmNHT7xz948pU8fCDLCuVq2CFi1Yee/ene92fBsfH1NSUuLu7jVqRFj9+oFEL6kx7S76amZycuKihavMTM23bFuXmPDSwNDwz3XweMdORLRqGTRsaCho9OCh7+Eza+Zi+OlhkSVfz+FyeWNGfwlzwnBC4stlX6+3sLA8ErH/ytULZmZ/Pne0fsOKU6ePT5o4q149/1u3rq9dt0wgEHQJ7l7JJkkkkpmzJ3p6eG/dvK9YVrxly9rsrEymSCaTTZk2VsAXLPlqjZm5xZkzv3y9bJ5IJG7dum1iUsLkqWPate08dsyk9LTXcCzJFfJxYydXsiJQtkSSd+zYkW9WbWGxWGPDhs2eOznAv+F3Ww/AMTzqs4GgSDgAFArF1OlhhYWFM8MXmZtbRBw9OC183JZNe52dXXk8HrOPEyfM8PMLuH3nJki2vl8gHNhzZi9ZsDB886Y9dewdCwoKZsya0KnjR5O+nAnaPfrTIajhh4MnRSIR0T9qxu9CDLt//+6QwSMbN2rm7u45e+ZX2TlZqlIOh2MgMBg5Ymzdun4QUT7s0gP+sDat29nb1WnUsGlQUMfbd26QssgNYWZA/2EBAQ0dHJzCxk6GmZkacvNyT/xy9JN+Qzp26GJna9+9W6/OnbruP7Cr8q26fuNyXl7uuLApLi5uXp4+47+YlifJY4pu3Lzy6tWL8OkL4EiAzQgZOgoGfj52GIpAggKBwcQvZ/h4+4KUIfgp5G950IDNZsNpYdCgT42NjI3ERs2atoLo+1lo6cnE2trGv36D2LinMNvNm1chvk6eNMvfv0HpDo6ZZGVlE/HjAVL6KE7pHwEHDARRUD/8jDY2tk+ePIRfQCgs1aWRkTEI9PXrlPz8fNAuyB12Cn6ipUvWqX4lfaNmdjulrCXh7e3LjIrF4nr1AjIy0lQzgGpVw4aGwmPHI65cOQ+eAf7yoqJC+GNg+ouXz+Db17c+Mxso3q9eADMxNjYa5mzSuIWqksCARr/8+lNRURFE3zdt1YsX8UKhEP5jZhSMAUQ7Zhj8AFgXNzcP1cw+3vV+P38aBp4+fQw7Amtnpnfu3BU+pAo4O7kyAyAycAiMSSgdFYtByjDwJPohxFfYcmY6KB5ic0xstKoGD3cv1TC4JslfR5oKUDx8Fi6eAYaqebPWsP16axhITWk3T5JLSv8zsWqKlaV1ee2WL1q+YgFExPHjpoFM+XzBvv07wBvA9IKCfPg2NDBUzQkqZwby80s7x50wMZT1V+8uzKP5mVkZEIbftFX5BfmqGhgM/qpcIpUw8UwFqJxZi1QqMTV9lz44yh9FjAdQwWwtrBS8SvCHLVXTwUVYWVmrRvn/PA7/2/0AHFFrV28Dx/XLL0e3bltfx95hxIix7dp2InpJzWgXDCt8y4r/fngaFFDhnBA+L1w8O3TIKFUwg6YSM8AISzVKSg3rn4GHkT5YZFcX9/K1WVpYkTcDRqWwXG3lt0osEv9rC6X5UmYtEC/BaZC3UVxU7adtwU6Ai9i8cU/5iWxO9TocggbA55+Nh8/Ll8+hLQhW2MXZzdXVnegfNeN3wTKSsrMtMyqVSqH9XuGcijJU51OY89q1S0yAcXRwhu/o6EdMEaj83v0/+yX38PAGVwdtcycnF+ZjbAx1mP0rvP0LJ0cXqB98LTMaG/tUlWzy9vKFNhNMUc386OF9H596MODp6QMpgqK/pPnryZ/HjR+hVCrhJA6LwMb/WVvcU1JNwJZADaUb9tde8Ph8OEFVvQZoR16+fP7PvXNyAVMOJ6LnL+KJXlIz2oXfEbzX93u/g+wSJKSWLJ1j9pez/BdwYoXGHGQMIG0J0gmfOb5FizYgqYSEl3D2BBexd9/2P25dfxrzBDJuqrMwRCxon23fsfH382dgwbuRtyZNGQ3eo/Ktat68NTiBNWuXPol+BMmyteuXqcxA06YtobkDNTx+8hAEAeff6KeP+/QaCEU9e/QFgS7+alZU1L1Ll3/fsnUdZCrAmzJu/uSpY/ANMY9p2FWLxo2bg6OFmiMjb0OK7bezJ0NDBx47fqTypYzLGgM3blx5/jwe2hVz508FzwAbAMck/FbgIry86hK9pMaaqHNnf71sxQKwpHAehxa3hbll+VZIeaZOmbty5aLhn/a1tbWHnKuXZ92oB5GfjR68fdshcAUrViycOetLOH1D+rZD+y6MFQbGjJ4ITbrNW9ZAihSaXJBxGzkirPJNgsg8f95ySDyN++JTGxs7aPgfOLibSRpAFIdM3LcbV02dNhZioZurx+KFq5hUK2QGoAjyu3B4QHSHRj2kt0hpqK4LqZIdOzdBEtfV1QPSF599PvitKYjylK50aWnNoD8wM7D7ISGhkKiufCmQJhxpG75dCSmzVSs3TZ0859DhPbAZUJuLi/vCBSvB9RK9pOL+yG78mimTkWr16QSpRwhXkGFgRidO+hyc2exZXxFEm4j8PVNgQJp20YXeumos7kKSHJo4kFoHyV67fglO63DNiSCI2qixuAuncjgFwwUhyNfa2zvAJdYqpkXfB7DXcMy8qXT/3uOq8wDCoEtxt8a0qxGKi4szMtPfVGpjbctm441y/wA9g7bA5/MruTaB6DZ4DyRCK6hdhFZQuwitoHYRWkHtIrSC2kVoBbWL0ApqF6EV1C5CKxVrV2DIJvh6NV2Eb8AWCHXkr634cr+JJS/leQFBdI6UZ/kmFjpysq1Yu3U8hHKZkiA6h1xWYu8uJDpBxdrlG7DqtzT+bQ/2gaVTnPk+yb+NCfy5RCd443vcgZdP8i/9lB7QxtzURiAUV+9xVkR7yJcosl8XR57PCOpt5ehlSHSFyrQLpCfBPmenviyUZmv+JbTKEiVsLIeSW3IVSiWLRdgszW+t0Jhj62LYsL2puS2f6BBv0a72kJ+fP3369LVraXqO6Isvvvj666+FQh3xl9oGHdqNiopycXGh8QEeiUTy/PlzPz8/gtQ0FJx/w8LCjI2NKX3yTFwGBGCC1DTaHncTymjevDmhmStXrri7u9va2hKk5tBe7b569erp06dBQUG60UenXC4/d+4cmAd7e3zArmbQUu1KpdJBgwYdPXqU6Bbdu3c/dOiQoaHuJKo0iDZqNykpSalUOjjoZldFsHfwjdH3/dG6ttqKFSsKCgp0VbikTLVwVlm1ahVB3g/t0i6kk0C10KwhOo2np6eNjQ0YeoK8B1rkGe7fv+/m5qY/vTBB6jc2NjYwUH873X9PtCLuFhUVNW3a1MvLS6+6D4OdhV1u0aKFTCYjSPXRfNxlrjzVrVuXw9HH232Ki4sh+jo5OWG3f9VFw3H3yJEjKSkpkPXUT+GSsi7VfH19ExMTdS8hqG40qV0It9HR0R4eHkTv8fb2fvDgAbbeqoXGPANc6WWz2ZjmLE9ycjJYCGdnZ4JUAc3E3X79+pmamqJw/4WdnZ2ZmdmAAQMIUgVqO+7CZf1r166BanU+ifvOPH36NCMjo0mTJnr7stUqUqvavX37toWFBbSpsTvyylEoFNAYyMvLw+xvJdSehqApvXnzZhcXFxTuW4GsC5yX1q1bB0kYgryBWoq7OTk50IjGxweqy8OHD+vUqQNtA4L8h9oIgdOmTWOxWCjcd6BevdLXxIaHhxPkP6g97l64cAGueXbs2JEg78rp06dFIlGrVq0IUg41ajczMxPaHAKBwNjYmCDvR25ubn5+voGBAfoHFeryDJDl+eSTTywtLVG4NQL8jNbW1r17987KyiJIGerSLlzhPHPmDNhcgtQQkJ85e/Ys/LAEKYOavkUQ5F+oJe5CXn348OEEUQMhISEvX74kiJr6PYcmmlQqJYgagB9WqcTuZUtRi2eAH7egoADSOgSpaUC7hoaGeG2SoN9F6AX9LmWg31WBfpcy0O+qQL9LGeh3VaDfRWgF/S5loN9VgX6XMtDvqkC/Sxnod1Wg30VoBf0uZaDfVYF+lzLQ76pAv0sZ6HdVoN+lgz59+nDLIGX9s8A3DIOIt27dSvQVtXgG8Lvz58/fsWMHQWqIoqIi+FXLT2GxWIMHDyZ6jFpOPeh3axw/P79/2VwnJydotxE9Ri3adXV1xaBbswwcOLBOnTrlp3Ts2FHPnxlWi3ahJYENtZqlfv36EHpVjRNHR8f+/fsT/Qbzu9QAodfa2poZ7ty5s5mZGdFv0O9SA4ReX19fCL0QdPv160f0HrXkGcDv7t69m2gNBXnKEqILqcD+fUMePYgL7tjDkG+an6cglAMOSGT87u8Z0eX8rkJWcvHH9Lh7edZOhq8TCgmiZQjF3Oy0IidvUcP2pvbu1X7Hslq0C353zpw5mg29RfnK7+Y86zzE3tSaLxDq6UuEtB+loiQnQ3b9xOtmnc2dfYXVWlZd9zMUFmoyzkEmdNvs+KFz8A1C2g6bwzKz5n843OHM90myYqVHYDVeMqeu+xmKi4sNDAyIhrh4JM3aRVzHo9qnIUSDnN6d2HtcnarPr678rgaFC8Q9kJpa8QhCFcUFyrSEoqrPr6787tChQ4mGgJ8ATkMiE3xJDmXAeTL7dTVeraybfvf1K8wq0EeBRCmXV+PWZL3I7yI6iVq0q3G/i+gDOuh3ET1BN/0uog+g30VoBf0uQivodxFaQb+L0Ar6XYRW0O8itIJ+F6EVdT2vhn73TSSnJH32+eBOwc0PH9lHkPdAXf0zUOd3P+7VEVRF1M/x4xGvEl58s3Jzp44fEeQ9QL9bSlJyYk5ONqkVJJI8O7s6fn4BBHk/1NUfmcafV6s6r169GDqsNwwMHNSjVaugRQtW9ujZbljIZzf+uBoZeevID6cNDQ137d5y9uzJ9Iw0ExPT1q3aho76gjk4e3zcPmTIqMTkhIsXzxYWFvj7N5w8cZa5uQUU3bt357sd38bHx5SUlLi7e40aEVa/fuCYsMhn+64AABAASURBVGGPH0dBabsOjUeNDBs4YNiDB5Fbv1v/9OljFotV18cPJtat6wczzJ4zmcfjOTo6H/phz5xZS2xs7EaM6v/1krUHDuyKiX0iEok/Cx1vY227dt2yhMSX9nYOkyfP9vaqW/me3r9/d826pS9fPofaQkeN239gl5enz5cTwh89ejB23PCN3+728fZl5uw/sFv7dsEwDwxnZKRv2rz6/oO7cHi7uXmGjhwXGNgIpkdEHNizb/ukL2cuX7kwuHO3qIf3xGKjpUvWqlYHu5CRmf7t+p1EPaDfJfb2DnNmL4GBzZv2hE9bAANcHu/YiQhPD+/Vq7aARg8e+h4+n38+Ycf2H6ZNnXfx0rntOzYyy/L5/H0Hdrq5ehzYd/y7rQdBgru/L+2YsaCgYMasCTB9w7qd8IGBaeHjJBLJsq/XBwd3c3V1PxrxW6//9YfDZvLUMSDBzRv3bNywGxQ5acrotLTXUAMIN/5ZbFx8DCziW88fRmHi9u3fThg//acfz/nXb/DN6q/giPpq8eqIw2dEYvH6DSsq301Y+6zZE83NLLZs2gv7+9NPPyQlJXB5b3m6BP7KqdPDHj2Omhm+aNuW/T4+9WBHXrx4BkUcLreoqPDoT4fCpy/438efdP3o41u3rmdmZjALwi/wx61rXYK7E7WBfpdwOByhsLQHKiMjY6YrKphiIDAYOWIshEAul/thlx7wf7dp3c7erk6jhk2DgjrevnODWRaCpYuzW7eu/4PZbGxsGzVqFh39CKa/fp2Sn58PjtbZ2dXFxS1s7OSlS9bBPGKxmM/jg6eC+A1HxdGffwC9wvHAzDZ92nzQypnffiGlDyFyEhNfQRFEaxNjE1ZZh7sdOnSBOWHz2gZ1Ai1269bLwsJSIBB80Lp9bGx05bt57fqlPEneuLApcORAuJ06ZW5ubg55GzdvXo2Pj508aZa/fwMHB6ewMZOsrGwifjxAyjpRhX3s3WtAs6YtbW3t2rXtDHt07vdTqtXBCQeCN1Eb6HcrhjlxMxgaCo8dj7hy5Tx4BrlcDsEGVK4qBT+gGoaTZm5eLgzA3wyfhYtn9Ojep3mz1m5uHiDB/64lJuaJt7cv06suAEeOk6NLXNxTZhQMg5HYqPz8zs5uzICw7BhzdHBWjcKJDnQPsiZv4OXLZ/CnODm5MKNwpIHuydt4Ev0QQn5gQCNmFP7ZAP+GMeWOE9UPBc4KlHrmzC99eg+EUTBRcLTDsUrUBvrdioFwqBpevmLB9RuXx4+b5utbn88X7Nu/48rVC6pSCHvlF2SVfYOG1q7eBk7jl1+Obt22vo69w4gRY9u17fSvteTnS62tbMpPMRQK8wvy/7sNDGBRyo/y/jla+SPfUC0chOWnCARvjy8SqUQmkwV/2FI1BY4QKytr1Wj5jfzoo4+Pn/jx2bM4aIzeuHllwfwVRJ3g/QxvAQLthYtnhw4Z1blzV2ZKQWFBVRY0MzP//LPx8IG20b79OxcsDIcw6eHhVX4e+ONBHOWnSKUSsL9EDYALgkOl/BTIeDAD4Hz+NXNR0Z/P60Lgh2gNdrx8KfsN0b2uTz13d0+wDR4e3sbGJuCviDpBv/sWFGWAPWVGpVLptWuX3tqpRWJSwuXL55lhOE1P/HIG6ENlBlR4e/mCP2b64AfAj4LQvf9q7Ncs4EZAkUwzi5SeG+NVfpeJnSplQ2IhOzuLGfbxrseEIdgL5gPB3srS+k1r+bBLT2jLQk6mc6eu6n4phm72z1BdjMv8640bV+Af/VcRWAKIJadOH4cccGzs0/CZ41u0aAPZooSEl6DpN1WYkpI0d/5U8AygRUgm7N23HVwEWI5/zdajR5+CgnzIMcE80CRatHgmOGY1XbNo3ry1UChcs3YpJA0iI28vW7FAdUDa2trD8OnTJ+AoAr8OKQuVoW/cuLmHu9fir2bBInDt5rezJ0NDBx47fuRNa+nU6SPYd2ioBaszw8CA9zOU4uVVt2nTlhu+XQnp0v+WQpNcIZcP/7QvtL369R08YvgYMKmfjR6cnp72pgrhdDl18pzTZ06Efj5o9Niht+/cXLhgJbS9/jWbQx3H5Us3QK5qZOiAsC+GQ2yGrJxKUjULVDt/3vLMrIzxE0auWLVoQP8Q1YrARkOK4+Gj+917th33xaft2wdDQ1P1RpZlS9c7u7jBoThseJ/v92wLCQllWmMVAlEgMLAxNOBg14iaUUufTnFxceHh4YcOHSKaoLhAuXPB8wHT3QhSKXBFpkmTFuPGTiY1B5iNAYO6Q2qvbVBHUk2u/vTaycegblPjKs6vlraam5vb3r17CaJPgNlITk6Ec5erq8cHbdoT9aMW7cK5j8fD7sBqG7i0Cxe93lS6f+9xtWZbjx+P2LlrM2SCp8ycUzuvLlSLZ3j27Nns2bP37NlDNIHeeobi4uKMzPQ3lULqTcvfhqkVnoHpw5QgtQs0uexs7YnegH4XoRX0uwitqMUAgd/V81fdIrUA+l2EVtDvIrSCfhehFfS7CK2g30VoBf0uQiu66HdLiLUj9oZGHwZiDpfLqvr8Ouh3+UJ2dlqxNEdOEKpIjM03teZXfX61aFfjfte9vijrNRpuqighBoZsKwdB1ZdQy31kUKdcLtesbVg/MTZkHr4LmxpO70oMbGvq7i+q+iJq0a42UFSg3DYzvuNge1MrvtAY38+qpciKlDnpspu/vm7ZzdLRu3rvLtfB+3dVlCjJxaNp8felZjb81Jc68sy9Uqkouw23Gm0arUVkzJHmKJx8hA3amtq6VLt5rcv5XRabBPWygg/EYKIrhISELFy40MnJidAPhE0D4bu3uPQivysw1OrnBaqFXFnAE+jUHr0zeD8DQit4PwNCK3g/A0IreD8DQivodxFaQb+L0Ar6XYRW0O8itIJ+F6EVtfjd+Pj4AQMGEARRJ2qJuyUlJZX0CY4gNYJatOvu7r5//36CIOpEXTe2VvKiLwSpEdDvIrSCfhehFfS7CK2g30VoBf0uQivodxFaQb+L0Ar6XYRW0O8itKKuuOvs7EwQNQB+jMXShY5F3h913b+7ePFigqiBuLg4Xe2Gq7qg30VoBf0uQiuY30VoBfO7CK2g30VoBf0uQivodxFaQb+L0Ar6XYRW0O8itIJ+F6EV9LsIraDfRWgF/S5CK+h3EVpRl989dOgQQRB1orPvE9YxGjduTMpOaKSse2NmuE+fPuHh4URfUYvfjYuL69evH0FqjkaNGoFYWWUwUxwcHIYMGUL0GHy1Jx0MGzbM1NRUNQo6btOmDciX6DHoGahh9OjRN2/eZOKuvb39pk2b4JvoMRh3qQEcgomJCTMMQVfPhUvQ71JEy5YtfXx8SFnQ7d+/P9F7MO7SxKBBg0QiUatWrRwdHYneozt+98rPGa+i87l8dkZSIdFd5HIFh8PW7e5FDMVca2eDhu1MrR0FlcymC9otyldunRXftq+d2IxrasUvURKEagok8py04sgLmS27WTjXFb5pNrVoF/wu5Mxr59JacaFy+9znA8PdsKMj3ePM90l1mxrBp8JS6v3uxYj0ToPtUbg6Sach9o9v5kJ4qrBULdqtzfsZom/lWjkYEERH4XBYSXEFFRap6/7d2iEzudjVT8zCZInuYusmyk6XVVhEd35XqSwBU08Q3aW4QFFcULFnoDvuIvoM3r+L0ArGXYRW8H4GhFYw7iK0gn4XoRWMuwitoN9FaAXjLkIr6HcRWsG4i9AK+l2EVvAWrGoQHx/brkPjBw8iidaTkPgKNvXW7Ruk1jl77hSsOk+SR9QM+l2EVtQVd7EfSETdqCXu1ubzatXi8JF9N29eXbZ0PTM6dFjv/Hzp4UMnmdG586bKFfLFC1dlZKRv2rz6/oO7OTnZbm6eoSPHBQY2UlWSlZ0ZPnNCZOQtgcCgS3D30FHj2OzKQoBMJtu8Ze2ly+eysjJNTc3ate08amQYl1v6yz9+HPXd9m+fxjxRKhUNApuEjZ1sY2PLLPXb2ZMHD+5OTHrF4/H9/ALGjJ5Yx760B6fZcybzeDxHR+dDP+yZM2tJixZtYGvXb1hx6/Z1NpvTILAxzGltbcNUUlhYsGBh+LXrl2B1XYJ7fP7Z+Mr79D4ScWDP3u8WzFsOFcKqTYxNhwwZCfvIlJ745SisNCkpQSgUNW3S4vPPJlhYWJLSR5flG75d+dtvvypLlC1afBDg31BVIRTt3LX54qVzqanJ1ta2fXoP7NmjD6kh1BJ3WSyWdvZ77u7u9fDRfeackJmZkZaWCsJKTEpgSkGsjRo2g9Kp08MePY6aGb5o25b9Pj71poWPe/HimaqSLVvXtWjeZsO6nZ/0G3Lw0PfHjkdUvtJ9+3ee+/3UlMlzdmz/YeKEGTD8/Z5tMD0pOXHSlNFcHm/dmu9Wrdycm5czeeoY2B4oevjw/uKvZrVp037rlv3Ll20oyM9fsGA6UxsIN/5ZbFx8zLKv1/vW8wdxwOalvk5ZtGAVHHUpKUkzZk1QPT8LugkIaASbOmjgp3DcXrr8e+WbyufzJZI82LwF81f8fPT3jh0/XLlqcVraayg6deo4DH/YpceunUcWLVgJx9uMmX+uCHbw+Ikf4cDbtvWAf/0GoH5VhXAMHInYP3TIqJ07DvfrOxhGT546RmoItWjXzc1NO9834ebqkZ+fD388DEfeu+3p6ePp4R1V1vZ6+fJ5dnZW40bNIDBDm2zypFn+/g0cHJzCxkyysrKJ+PGAqpJmzVr16N7bzc1jQP+QevX8z547WflKnz+P83D3gpohcDZv3nrl8o2dOnWF6T/99AMc4TNnLHJ2dvXy9AmftiAh4SUjLxcX9y2b9w4aOBwWgaL//e8T0EpObg4UsTmcxMRX06bOq18/0MTY5Nat63FxMZMnzgoIaAjheeLEmc5OrunpacyqmzRuAXEONrX/J0MtLa0gzFe+qXACgYNhyOCREP5hODi4O4zGxT2Foh+O7G3dqi3UY29XB1YNSoVNYio8feYEFAUHd7OztYdfpr5fIFNbbl4uhGo4wjt26AJF3bv16typ6/4Du0gNoV9+18TEFOTIiPX+/Tt1ffzq128A4RZG792/A6daJyeXJ9EPIbYFBvxpEuAvhJNgTGy0qpJGDZqqhn3r1gfRV75SCNJ/3Lq+cNEM0KVEIoFVONQp7dXm8ZMo2AAj8Z8PcNva2oFSGaGIRKJncPxMGfPJgK49/9dh6bJ5MDEvL5eZEwyDaikQkIGBAaiTGQWhz571lZWVNTPqVy9AtRnGxiZSqYRUAbBJzICRkXHpeiV5oGA4nuHYUM0DWw7fsXFPS09cia98feurivz/8gyxsdGwIBw/qiL4VeHnKioqIjWBfvldoFHDpg+iInv16g9xF4yswMBg9ZpfSZl2wTDAgEQqgf8j+MOWqkXgOFSpgZQKS6waNjQ0LCp6Szc8nTt3hUV+PnZ40eKZSqUy6IMO48KmwFEEVjsq6l7nLn//tbDejMx0GPj52JFvVi8ZMnjWmtNrAAAQAElEQVTEF+OmwrL37t3+6us5FW4AnOINDd/Y+wbsnWoYjFwV++IQCP7ZG01JSUFhASxbfkWw4/BdUJAPRTBgYGBYrujP2WAH4XvCxFBVLz7MBmRmZUAYJu+NWrSrtX4XaNCgybr1y8EeQADwqx/I5XCTkxOhFRUVFTlq5DiYAUIaRLLNG/eUX4pdbneYf4sBHAg0XN660latguBTWFh4/cZlWPuKlYsWLlghFhtBRP9ywj86LmdqAx8Cra5Ph49mJkIL8k01wzEA8mW6lSZqw9DAEM4/5cO2tEyXcBQZCEoPj8Jyv4nkr8wuc4zNmrnY1cW9fG2WFlakJtAvvwsEBjaGVtqp08ddXd2NjYyFQqG7myc4ttTUFAjJMIOPdz0QGQzAyZ358Ph8K8u/4y6oXDUM533wl5WsDlR1+cr55JQkUhqcDNoGdYTmDmMMYEXQlre3d1CtCPRnbm5BygIwiFJVydmzJ5m6/ls/WHaY+dGjB8wonNlHhg549iyO1CiQpgDLDi1I1ZRHZcPe3r7QvLO1sYuOfqQqunPnJjPg4eENC0KuRrWD4FtMTM3AkpGaQO/yu9C+gfYZtL2gRcxMgej749GDMBESWKT0zQ7N4X+CZn5k5G3QHOSqQkMHHjt+hPx1yoOMz/kLv6WkJP949BD8nWAJKlkdyBHySpCoYmqDb1jcP6DUEfbs2RdC1NfL5oGZhlbart1bh4/oB/4ViurW9bt95ybkOmARaN1DdgkmPol+9F+n2KRxczC7y1cuBEt9//7dFasWkbKjjtQ0ffsOvnL1wg+H98KO3428tW7DioYNmsCPBkXt2wfDTkGzDI4cSLwwRyYpO4NB+2z7jo2/nz8DSRVYCvIqy1csIDWE3vldUmYb4CdWNSmgQRMRcaBtUCdmFEIFJIA3bl49d/5UOBXa2tqHhIRCYhKKimWlfUGAW4V809dL54LJG1ou/fkm5s1Z+u3GVfMWTINzLiREW7b4YMSnY2E6eL5vVm3ZsmXtF+NHgMWC3MJXi1f7ePtC0dDBIyHbNXnKaLAQPbr3GTzoU0jnLVs+n8kKlweOjSWL10Duad78qRwOF0wIbJ46DBvkCsDZw3EIKUIwA5BYgPwuUwQpMPBgGzd9A24eGqahoV/MXzBdIS/1OZBshgbf5i1rIAkNp5RWLYNGjggjNYRa+tKLj4+fOXNmLdiG9MSiM3tSu33uRBAdJfL3THDUTbuY/7dILXFXm/0uojOo6/5d8Lv680phcCDlLyaVx9XVY+3qbURrmDVnEmTcKiwCcwIXqwk96KPfrXE+7tnvo48+rrCIrWUd/c2YvlChrLgZzePWTPO/1tC7/K46EJRBaABygkRXQL+L0Arev4vQirqeVxswYABBEHWCfhehFfS7CK2g30VoBf0uQivodxFaodzvlhAjSzouCiDvBt+Q/abrfXT7XTMb/qsnVXoGC6GU9IRCI9OKIyzdfpfDYzn5CCVZcoLoKCUlxLJOxadW6vtnaNTB7PyhZILoIrdPZ5jb8MxsKjYNarn3vJZJiiu8EJHWYYCdoRF2yaojFBco757PEIrYLbtbvGkedWm3lu/fTX5WePu3rMTYfEcfcW66Lr+lVaFUsNlsFtHlF9cXSBTgBv1bmwS2Na1kNrVoV1P378qKlFmvZYT6E0llTJs2bcKECXZ2dkR3ERpzRCbctz60r5aTLAQGPp9Pah2egG3tqOMpszxZgokNsXbCzKB6tOvq6rpnzx6CIOpELXkG8CFMf4YIoj7Uot34+PhBgwYRBFEnOuV3Eb0C/S5CK+h3EVpBv4vQCvpdhFbQ7yK0gn4XoRX0uwitoN9FaAX9LkIr6HcRWkG/i9AK+l2EVtDvIrSCfhehFfS7CK2g30VoBf0uQivodxFaUYt2U1NTR48eTRA1YGJiokvvmXof1NUvzv379xUKRYMGDQhSc/Tv33/27Nn16tUjiFr7I5NIJCkpKRYWFmZmZgR5P9LT0z/++OMdO3Z4enoSpAw1vjFULBa7ubn17ds3OzubIO/B3bt3Bw8e/Ntvv6Fwy1Mb/UDeunXLx8cHpEyQ6vNzGdu2adELtbWE2nhTc+PGjQsLCzdt2kSQarJhwwYIuijcCqmlt4xbWlpyudx79+4RpMpMnz7d0NBw7ty5BKmIWu07OikpCa63gY4J8jbA4IaEhHTq1Ikgb6CW4i6Dvb09pCfbt28vl+MbIt5IVlZWUFDQrFmzULiVo4E++3Nyci5fvhwcHAwugiD/BPLiEydOPHr0KDZt34rG3jcBibPr16936dKFIH9x4sSJw4cPQxKXIFVAY5HP1NT00qVLjo6OeJWIAfIw0B5A4VYdDb/nJyoqysPDw8DAgOg34G6dnZ1HjRpFkCpTq221/+Ln58fhcEaMGEH0mGHDhrVu3RqFW1204v1qkZGRsbGxffr0IXpGXl7exx9/vGbNGjiGCVJNtOXdgHDhjc1mP3/+3MvLi+gHjx49GjNmDKQUwPoTpPpo2DOoAMsLly3gGhLIl+gBp06dWrJkyfnz51G474y2aJdh//798fHxRNfZtm3bhQsXvv/+e4K8B9qlXQCuusH3ggULVFPatGkzZMgQQi3Dhw+H62Sq0Xnz5slksq+++oog74fWaZchICDgp59+goGPPvqooKAgJSXl1q1bhEJu3ryZkJAglUo//PBDGIWMSuPGjfGBqBpBS6/K9uzZMzExEdrgr1+/JmWX+EHK8K8T2vj5559h42EgLS2tSZMmW7duDQwMJEhNoKVxF4DL+hCxVKOQRwM1E6qA62QPHjxQjUJKB9pnBKkhtFe7MTEx5UfBNkDbnFDFiRMnQL7lp0AamyA1hJZqFzyDSCQqKYOZAgO//voroYrTp0+X3374hp3q1asXQWoCLfW74G7hj4f22d27d+GyRXp6OrTNwfueO3eOSURoP7D94HGVSiXkra2srIyNjb29vZs1axYcHEyQmkDz19UeXstNiClQKksyU4ornEEul8mKZYVFhcXFxXwe38zcnNBAZmaGTCbn83kCQelllzfdrGxuy2ezWY6ehr4tjAlSHTSpXVjzkbUJ9h4ikQnXwt5AqdCKq9O1DAg3I7kwP0eeGCvt84UDYRGkimhSu4fXJPg0NXP2FRGEkOdRkpi7Ob3C6hCkamhMuzdOZnL5XK9GeKL8m+ibOSUlyiadsRuhKqGxPEPMnTwbZ0OClMPG1fDp7TyCVA3NaFcuJwYijokljyDlMLXiC4RsOfb+WjU0o12lTPmmrIKek5larJArCVIF8ClzhFZQuwitoHYRWkHtIrSC2kVoBbWL0ApqF6EV1C5CK6hdhFZQuwitoHYRWkHtIrSC2kVoRXufcaeC+PjY/gO7EUQTYNx9L6KfPiKIhqBJuz/9fHj/gZ1ZWZn1fP0njJ8eMrzP3Dlftw3qSEofKD9xJGL/y1fPhUJR+3bBIz4dw7wHYM7cKRwOp0GDJod+2JOZme7k6PLFF9N865Z21CyXy3fu2nzx0rnU1GRra9s+vQf27PFn59U9erYbFvLZjT+uRkbeOvLDaUNDw127t5w9ezI9I83ExLR1q7aho76A+r/b/u2evdth/nYdGo8dMxFqyMhI37R59f0Hd3Nyst3cPENHjgsMbEQQ9UCNdu9G3lq95uvevQb06N778eOo+Qunw0TmwfHzF35bsnTuoIHD581blpDwcvmKBXmS3OlT50ERn8+/c/cPEPTmjXtAxLPnTFq2fP7O7T9A0foNK06dPj5p4qx69fxv3bq+dt0ygUDQJbh7abU83rETEa1aBg0bGgoaPXjoe/jMmrnY3d0rOTlxyddzuFzemNFfDhr4aX5B/uXLv2/ZtNfAwFChUEydHlZYWDgzfJG5uUXE0YPTwsdBkbOzK0HUADV+98yZXywtrUAxTk4uwcHd2rRupyrav39nQEDDkSPG2tnaN2ncfNSIsFOnjkMILC1jsYqKCseFTRGJRKDC9u2DX7x4BvLKzcs98cvRT/oN6dihCyzVvVuvzp267j+wi6kQVG4gMIAK69b1g8Pjwy49QIKwRnu7Oo0aNg0K6nj7zg1S1t+1gC9gsVgQjEH3N29eBfs7edIsf/8GDg5OYWMmWVnZRPx4gCDqgZq4m5KS5Onpw2b/ebA1bdpq1+6tpOzUHxMbDSZBNWdAQOlpOi4+xsKi9OWvDnWcVO8RMjIqfSw5Ly/3VcILWLBJ4xaqpQIDGv3y609FRUWgQhitW/fvF0AYGgqPHY+4cuU8eAZYCg4Gpp5/8ST6IY/HCwz40yTApgb4N4RtI4h6oEa7uXk5FpZWqlFrKxtmoKCwoKSkZMfOTWBJy88P7pYZ4JdpsTwwf36+FAYmTAyFqKmaWLpUVgaEYVLacdjfr5UEE3L9xuXx46b5+tbn8wX79u+4cvUC+Q8SqUQmkwV/2FI1BVyElZU1QdQDNdrl8fhy2d9P0Eokfz4LbmhgCBGub59BcGYvP7+ZuUUltTHSBAvr6uJefrqlhdW/5oRAe+Hi2aFDRnXu3JWZAkdLhXUaiY0gwIOxLj+RzeEQRD1Qo13wmtHRfyekLl3+nRkAP+rl6fP6dQr4YGZKcXExnNxBSZXU5uHhDQtCNkC1VHZ2FovNhpP+v+ZUlAGOlhmVSqXXrl2CJuB/6/TxrgdOGgZUdSanJJmbVXYIIe8DNW21Dz7okJiUAB43KTnxt7Mnr167qCrq3z8EUg379u989erF05gnXy2Z/cX4EQUFBZXUBsqG9tn2HRt/P38GKoQkxqQpo8Eb/HdOsL/u7p6QkYDZYmOfhs8c36JFGxA9JDRA02KxUWZmxoMHkSkpyY0bN/dw91r81azIyNugWtjI0NCBx44fIYh6oCbuBn3QAXKuPx49ePDQbmiNTfxyRuhng8BIMEXh0xdA6hdcL5iB+n6B36zcDEnZyiscM3oiNLk2b1kDGQlIaUFGbOSIsArnnDpl7sqVi4Z/2tfW1n7UyDAvz7pRDyI/Gz14+7ZDHdp3AVlPnPz5wAHDhg/7fNnS9Rs3r547f2phYQHMHBISCklfgqgHzfRHVlyg3Lng+YDpblVfBLYTIhyTOgDu3787/stRu3YcVp2gdYP9S+NDZrsIDPFa/duh5jeCSwx9+nX5fs93CYmvoqLufbtxFbT6HR2dCaKvUOMZ4KIAXCo7+MP3e/dtB5cJadTPP5ugynAheghN9zPA5TT4EAQpA+8jQ2gFtYvQCmoXoRXULkIrqF2EVlC7CK2gdhFaQe0itILaRWhFM9otKWGJzfCwqQAjU56mX/BMDZq5F0cgZEmy5MWF+DKmfwA/SF6WzECIN5FVCY39TI7ewtwMfAveP8hJlzn54NuVq4rGtNuog9n1468JUo5rx1IbdzQlSNXQ5HvcE54WXj2e3nmoA0fv382qkJFTuxNa97Ss425AkKqhSe0CLx7n3zmXLc2ROXiLpNkKoglKSkptN4ulmVOQ2JT7KloiMuE16mDqWotzuQAACAdJREFU5CMkSJXRsHYZslKLs17L5DLNNN3Onj0L3x06dCCagMNlm9vwzGz4BKkmWpGogn9Og3/e+VultturoRFBqAKTrAitoHYRWkHtIrSC2kVoBbWL0ApqF6EV1C5CK6hdhFZQuwitoHYRWkHtIrSC2kVoBbWL0ApqF6EV1C5CK6hdhFZQuwitoHYRWkHtIrSC2kVoBbWL0ApqF6EV1G7p266VSuzVjz5Qu6SoqIggFILaRWgFtYvQCmoXoRXULkIrqF2EVlC7CK2gdhFaQe0itILaRWgFtYvQCmoXoRXULkIrqF2EVlC7CK2gdhFaQe0itKIV77XUCB999FFqaiqLxVIqlWw2G34HGLaysvr1118JQgMae4+7xgHtcjgcGADhktL3CbPgu0uXLgShBP3Vbq9evRwcHMpPcXZ2/uSTTwhCCfqrXXt7+6CgoPJT2rZta2trSxBK0F/tAv369XNxcWGGnZyc+vTpQxB60Gvt2tnZtW7dmhlu3749jBKEHvQ9Rwah98qVK5BqAPtLEKqgKUeWGFeYllAkyZbnZctJCSkuVJCa4FVCAtTm6OhAagK+IYdFWGJTjtiUa1VHUMfDgCDqgQLtPo/Kf3A9NyFaamwtZHE4PAGHK+By+ZySEm3szIbFYsuL5fIihaxIoZTL89ILHL1Efi2NXXyFBKlRtFq7CTEFFyLSuYYCgdgAhMvmsAhtKOUluWnSorwiRVFxUC9LDMM1iJZqF0Lqye/TUl8VWbubC00FhH7ys4tex2baOguCB1ux9LqFXGNoo3aVSrJ70QsLFwsjK0OiW+S+zs96lRUyy4kg743WaVcuU26f+8K5oZ1AxCO6SKFE9upu8qcLXDhc+iyQVqF12t0wKda3vQuLrcv/q1JREn3hxejl7gR5D7RLu/uWvTJzsjA00QWDWzlgf3MSMgZMcSTIu6JFrYZrJzJFVsb6IFwAGqBCC+Prv2QS5F3RFu3CFYeoazkmtmKiN5jYie9fzpHm1swVFj1EW7R7MSLdys2C6BmQAYQdJ8g7oRXazX4ty80uMbUTEa0kNzd98uxmUY8vkJrG1F6cnaHMTZcRpPpohXbjoyQsrp7eFcTicuKipASpPlqh3ZhIqdhSTy/3iy1FsZGo3XdB89GuuFAJ0Udkpq4L/XDGP3Zq7bMXkdL8bDsbz486j/FwbQTTL107ePbCjpABXx898U1G5iuR0LRj20+bNOzGLHXtZsTZizsl0izHOr7B7UOJ2hCbG0hSiLy4hMvHSxXVQ/PahQxDfp6cqAeFQrF19/hiWeHAPvONxBZXbvywbfeEL0fvtrF25XL5BQV5Z85vHzZwqYmx9Znftx3+eYmne1NTE+v453ePHFsa1GpQiya9MjITjp1cS9RJfm7pXZ1m1rp5HVF9aN4zQJKIK1DXIRQdcy05NbZvzxluLg2sLJ16fPilqYnN5euHoIjNYiuU8k5tPzUztWWz2Y0bdFUo5EkpMVB0O/JXEPpHncZaWjh4ezZv3uRjok54BhyQL0Gqiebjbn6eQiBU12a8SnzE4fDcXRsyo6BREHFi8lPVDOAimAGhoTF8FxbmwXdq2nNHB1/mCXgAFiHqRCDiwY9AkGqiee2yWeD21HUXeUGhRKGQTZ/fRjVFqVSAQ1CN8nj/uIzHXCEvKpKamdioJgr46m1HyoqUeFfkO6B57QqNOfJidUUdQ0MjPs9gwuhd5Sey2ZzKl+LzDYtkBarRgrJgrD7kxXKRMXauVW00/5OJTLiyInVpF7IE0FCDWGpj5cJMycxKAi9b+VJWFk5P424wvTzBaGz8H0SdyAoVImMOQaqJ5s9VJhY8Hk9d6SFvj2b2tl77D8+NfXYbVHvn/qlV3w659kdE5Us1CAjOzUuH9AK08+5Hnbt1V509lJUQvgHbyByTDNVG83EXrJ6JJS8vLd/IquZtJYfDHRWy5vjJtbsPhBcXF5ib2nduN/KDlgMqXwoU373L+AtX9kJOzcHep9/HM77ZOBSyEEQN5L7Oh+wYC3O71Ucr7t99eC3nwfVCWx9Lon8kP04LbC2s29SYINVEK9q37v5GRKmvSSKlwr2+Ht35WYNoRfPWQMSu48Z//SLHwtmkwhkg1bV4Zc8KiwwNjAsKcysssrPxGDtyM6k55izprHzDMaZq2P0La0uXLz77jryB9GfZjp4GfEPMkL0LWvPMTwlZPzHWr7NrhYVKpTI7J6XCIpm8mMflV1gEVyVMjK1IzZGZlVy6oRVuhqyYx6tgM9hsLlxkrnARqCnqzLOwbzwI8k5o0fNqDy7nxD9WmDiYEP0gOyHbox7PryU63XdEi85W9VubGAhkOSkSogdkJ+cJDRUo3PdBu5xW8FAbaVpubmo+0WlykqWFmZLOg60J8h5oY784h1YnCozFJna62frOTpYopNLe4+wJ8n5oaX9kv+xMLZLxzHTO+2a+zBYayLuE2BDkvdHefiDvXcy5eizdxtPc3FEXTGHGy9zUmMxWPS0D2uhLY1TdaHUfprLikks/pqcmyAiHZ2wlFJnT1wGoNLMwN01K5HJbJ16b/1lyeXjxt8agoO9oSbb86R1JTKQkP0/JYrO4AsjbcrkCrlKhjX1HczhsWZFcISvtPlqpKBGbcDwCRV4NjMSmeKdYDUNTn/3FhSWZKUX5uQpprlwmUypk2rjlXB6HyyMiY67QmGNuK+AbYKBVF/r7TlaEdvB2fYRWULsIraB2EVpB7SK0gtpFaAW1i9DK/wEAAP//bwrAFQAAAAZJREFUAwB8GTQG1jW6dwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the graph\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "# Run\n",
        "inputs = {\"question\": \"What are the types of agent memory?\"}\n",
        "for output in app.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        # Node\n",
        "        pprint(f\"Node '{key}':\")\n",
        "        # Optional: print full state at each node\n",
        "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
        "    pprint(\"\\n---\\n\")\n",
        "\n",
        "# Final generation\n",
        "pprint(value[\"generation\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "zfZ0OaNEAI6t",
        "outputId": "d772c393-dbbe-422d-ab6a-c9eb64f4125f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Checkpointer requires one or more of the following 'configurable' keys: ['thread_id', 'checkpoint_ns', 'checkpoint_id']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-8641146c64b8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"What are the types of agent memory?\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2370\u001b[0m                 \u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2371\u001b[0m                 \u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2372\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2373\u001b[0m                 \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2374\u001b[0m                 \u001b[0mstream_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36m_defaults\u001b[0;34m(self, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m   2183\u001b[0m             \u001b[0mcheckpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheckpointer\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2185\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2186\u001b[0m                 \u001b[0;34mf\"Checkpointer requires one or more of the following 'configurable' keys: {[s.id for s in checkpointer.config_specs]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2187\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Checkpointer requires one or more of the following 'configurable' keys: ['thread_id', 'checkpoint_ns', 'checkpoint_id']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# Run\n",
        "inputs = {\"question\": \"How does the AlphaCodium paper work?\"}\n",
        "for output in app.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        # Node\n",
        "        pprint(f\"Node '{key}':\")\n",
        "        # Optional: print full state at each node\n",
        "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
        "    pprint(\"\\n---\\n\")\n",
        "\n",
        "# Final generation\n",
        "pprint(value[\"generation\"])"
      ],
      "metadata": {
        "id": "SI3dXt7tAPcB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "5cb1c1fe-7659-4a72-adf8-739a5990a42e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Checkpointer requires one or more of the following 'configurable' keys: ['thread_id', 'checkpoint_ns', 'checkpoint_id']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-8ce48a42a91d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"How does the AlphaCodium paper work?\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2370\u001b[0m                 \u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2371\u001b[0m                 \u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2372\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2373\u001b[0m                 \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2374\u001b[0m                 \u001b[0mstream_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36m_defaults\u001b[0;34m(self, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m   2183\u001b[0m             \u001b[0mcheckpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheckpointer\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2185\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2186\u001b[0m                 \u001b[0;34mf\"Checkpointer requires one or more of the following 'configurable' keys: {[s.id for s in checkpointer.config_specs]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2187\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Checkpointer requires one or more of the following 'configurable' keys: ['thread_id', 'checkpoint_ns', 'checkpoint_id']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(graph, user_input: str, config: dict[str, dict[str, str]]):\n",
        "    # The graph expects 'question' as input key, not 'messages'\n",
        "    for event in graph.stream({\"question\": user_input}, config=config):  # Changed input key to 'question'\n",
        "        print(\"EVENT\")\n",
        "        print(event)\n",
        "        print(\"--------------\")\n",
        "        for value in event.values():\n",
        "            print(\"VALUE\")\n",
        "            print(value)\n",
        "            print(\"--------------\")\n",
        "            # Access the generation using the correct key\n",
        "            print(\"Assistant:\", value.get(\"generation\", \"No generation yet.\"))  # Changed to access generation from value\n"
      ],
      "metadata": {
        "id": "DiA_2nxckdsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"2\"}}"
      ],
      "metadata": {
        "id": "vtYF0OfHpuTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        stream_graph_updates(app, user_input, config)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(app, user_input, config)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCOGMQZCpgzh",
        "outputId": "a5aba1cd-1c50-4767-a8e2-c5dd7e81ab4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: agent memory?\n",
            "---RETRIEVE---\n",
            "EVENT\n",
            "{'retrieve': {'documents': [Document(metadata={'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.'), Document(metadata={'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.'), Document(metadata={'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.')], 'question': 'agent memory?'}}\n",
            "--------------\n",
            "VALUE\n",
            "{'documents': [Document(metadata={'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.'), Document(metadata={'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.'), Document(metadata={'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.')], 'question': 'agent memory?'}\n",
            "--------------\n",
            "Assistant: No generation yet.\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
            "EVENT\n",
            "{'grade_documents': {'documents': [Document(metadata={'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.'), Document(metadata={'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.')], 'question': 'agent memory?', 'web_search': 'Yes'}}\n",
            "--------------\n",
            "VALUE\n",
            "{'documents': [Document(metadata={'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.'), Document(metadata={'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.')], 'question': 'agent memory?', 'web_search': 'Yes'}\n",
            "--------------\n",
            "Assistant: No generation yet.\n",
            "---TRANSFORM QUERY---\n",
            "EVENT\n",
            "{'transform_query': {'documents': [Document(metadata={'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.'), Document(metadata={'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.')], 'question': \"What is the function of memory in an agent's system?\"}}\n",
            "--------------\n",
            "VALUE\n",
            "{'documents': [Document(metadata={'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.'), Document(metadata={'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.')], 'question': \"What is the function of memory in an agent's system?\"}\n",
            "--------------\n",
            "Assistant: No generation yet.\n",
            "---WEB SEARCH---\n",
            "EVENT\n",
            "{'web_search_node': {'documents': [Document(metadata={'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.'), Document(metadata={'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.'), Document(metadata={}, page_content='Memory is a cognitive function that allows people to store, retrieve, and use information to understand their present and future. Consider the frustration of working with a colleague who forgets everything you tell them, requiring constant repetition! As AI agents undertake more complex tasks involving numerous user interactions, equipping them with memory becomes equally crucial for efficiency and user satisfaction. With memory, agents can learn from feedback and adapt to users\\' preferences. [...] | Procedural | Instructions | Instincts or motor skills | Agent system prompt |\\nSemantic Memory¶\\nSemantic memory, both in humans and AI agents, involves the retention of specific facts and concepts. In humans, it can include information learned in school and the understanding of concepts and their relationships. For AI agents, semantic memory is often used to personalize applications by remembering facts or concepts from past interactions. [...] When do you want to update memories?\\nMemory can be updated as part of an agent\\'s application logic (e.g. \"on the hot path\"). In this case, the agent typically decides to remember facts before responding to a user. Alternatively, memory can be updated as a background task (logic that runs in the background / asynchronously and generates memories). We explain the tradeoffs between these approaches in the section below.\\nMemory types¶\\nPractical: Memory underlies many of our cognitive functions. Far from being just a storage system for past events, memory actively helps us think about the future and make decisions. Drawing on past experiences lets us simulate possible future scenarios and apply lessons learned when facing choices. In fact, memory is involved in everything from problem-solving and communication to social skills like empathy - suggesting it\\'s woven into nearly every aspect of complex thought. Without memory, [...] Memory also enables meaningful personalization. When an AI agent remembers your preferences, history, or goals, it can tailor its responses specifically to you. A personal assistant that remembers your favorite restaurants or previous travel plans can make more relevant suggestions. A recommendation system that recalls your past ratings can better predict what you\\'ll like. In technical terms, long-term memory lets agents store historical data and user profiles, which directly improves their [...] Memory in AI doesn\\'t just produce better task performance – it shapes how users emotionally relate to and trust the system. An AI agent capable of remembering and learning over time tends to feel more human and empathetic.\\nMemory in agents is one of the main tools to allow planning that is grounded in the relevant context and there are many aspects to memory that you should take\\nMemory in this context is a set of tool commands for updating a list that gets inserted into the system prompt across chat sessions. https://\\nIn summary, short-term memory is associated with working memory, while long-term memory encompasses episodic memory (experiences), semantic memory (knowledge), and procedural memory (skills and procedures) in AI agents. These memory components work together to enable the agent\\'s cognitive capabilities and performance across various tasks. [...] Reduction in redundancy: Memory systems help avoid redundant processing by recalling previously encountered information, thus improving response time and resource utilisation.\\nAdaptive interactions: AI can adapt to users\\' changing needs and preferences over time, offering more relevant and accurate responses. [...] Contextual awareness: Short-term memory bridges the gap between interactions, allowing agents to recall recent user inputs and tailor responses accordingly. This is akin to human working memory, where immediate past interactions inform the current response.\\nFacilitate long-term learning: Long-term memory stores past experiences, enabling agents to build knowledge and improve decision-making over time.')], 'question': \"What is the function of memory in an agent's system?\"}}\n",
            "--------------\n",
            "VALUE\n",
            "{'documents': [Document(metadata={'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.'), Document(metadata={'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.'), Document(metadata={}, page_content='Memory is a cognitive function that allows people to store, retrieve, and use information to understand their present and future. Consider the frustration of working with a colleague who forgets everything you tell them, requiring constant repetition! As AI agents undertake more complex tasks involving numerous user interactions, equipping them with memory becomes equally crucial for efficiency and user satisfaction. With memory, agents can learn from feedback and adapt to users\\' preferences. [...] | Procedural | Instructions | Instincts or motor skills | Agent system prompt |\\nSemantic Memory¶\\nSemantic memory, both in humans and AI agents, involves the retention of specific facts and concepts. In humans, it can include information learned in school and the understanding of concepts and their relationships. For AI agents, semantic memory is often used to personalize applications by remembering facts or concepts from past interactions. [...] When do you want to update memories?\\nMemory can be updated as part of an agent\\'s application logic (e.g. \"on the hot path\"). In this case, the agent typically decides to remember facts before responding to a user. Alternatively, memory can be updated as a background task (logic that runs in the background / asynchronously and generates memories). We explain the tradeoffs between these approaches in the section below.\\nMemory types¶\\nPractical: Memory underlies many of our cognitive functions. Far from being just a storage system for past events, memory actively helps us think about the future and make decisions. Drawing on past experiences lets us simulate possible future scenarios and apply lessons learned when facing choices. In fact, memory is involved in everything from problem-solving and communication to social skills like empathy - suggesting it\\'s woven into nearly every aspect of complex thought. Without memory, [...] Memory also enables meaningful personalization. When an AI agent remembers your preferences, history, or goals, it can tailor its responses specifically to you. A personal assistant that remembers your favorite restaurants or previous travel plans can make more relevant suggestions. A recommendation system that recalls your past ratings can better predict what you\\'ll like. In technical terms, long-term memory lets agents store historical data and user profiles, which directly improves their [...] Memory in AI doesn\\'t just produce better task performance – it shapes how users emotionally relate to and trust the system. An AI agent capable of remembering and learning over time tends to feel more human and empathetic.\\nMemory in agents is one of the main tools to allow planning that is grounded in the relevant context and there are many aspects to memory that you should take\\nMemory in this context is a set of tool commands for updating a list that gets inserted into the system prompt across chat sessions. https://\\nIn summary, short-term memory is associated with working memory, while long-term memory encompasses episodic memory (experiences), semantic memory (knowledge), and procedural memory (skills and procedures) in AI agents. These memory components work together to enable the agent\\'s cognitive capabilities and performance across various tasks. [...] Reduction in redundancy: Memory systems help avoid redundant processing by recalling previously encountered information, thus improving response time and resource utilisation.\\nAdaptive interactions: AI can adapt to users\\' changing needs and preferences over time, offering more relevant and accurate responses. [...] Contextual awareness: Short-term memory bridges the gap between interactions, allowing agents to recall recent user inputs and tailor responses accordingly. This is akin to human working memory, where immediate past interactions inform the current response.\\nFacilitate long-term learning: Long-term memory stores past experiences, enabling agents to build knowledge and improve decision-making over time.')], 'question': \"What is the function of memory in an agent's system?\"}\n",
            "--------------\n",
            "Assistant: No generation yet.\n",
            "---GENERATE---\n",
            "EVENT\n",
            "{'generate': {'documents': [Document(metadata={'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.'), Document(metadata={'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.'), Document(metadata={}, page_content='Memory is a cognitive function that allows people to store, retrieve, and use information to understand their present and future. Consider the frustration of working with a colleague who forgets everything you tell them, requiring constant repetition! As AI agents undertake more complex tasks involving numerous user interactions, equipping them with memory becomes equally crucial for efficiency and user satisfaction. With memory, agents can learn from feedback and adapt to users\\' preferences. [...] | Procedural | Instructions | Instincts or motor skills | Agent system prompt |\\nSemantic Memory¶\\nSemantic memory, both in humans and AI agents, involves the retention of specific facts and concepts. In humans, it can include information learned in school and the understanding of concepts and their relationships. For AI agents, semantic memory is often used to personalize applications by remembering facts or concepts from past interactions. [...] When do you want to update memories?\\nMemory can be updated as part of an agent\\'s application logic (e.g. \"on the hot path\"). In this case, the agent typically decides to remember facts before responding to a user. Alternatively, memory can be updated as a background task (logic that runs in the background / asynchronously and generates memories). We explain the tradeoffs between these approaches in the section below.\\nMemory types¶\\nPractical: Memory underlies many of our cognitive functions. Far from being just a storage system for past events, memory actively helps us think about the future and make decisions. Drawing on past experiences lets us simulate possible future scenarios and apply lessons learned when facing choices. In fact, memory is involved in everything from problem-solving and communication to social skills like empathy - suggesting it\\'s woven into nearly every aspect of complex thought. Without memory, [...] Memory also enables meaningful personalization. When an AI agent remembers your preferences, history, or goals, it can tailor its responses specifically to you. A personal assistant that remembers your favorite restaurants or previous travel plans can make more relevant suggestions. A recommendation system that recalls your past ratings can better predict what you\\'ll like. In technical terms, long-term memory lets agents store historical data and user profiles, which directly improves their [...] Memory in AI doesn\\'t just produce better task performance – it shapes how users emotionally relate to and trust the system. An AI agent capable of remembering and learning over time tends to feel more human and empathetic.\\nMemory in agents is one of the main tools to allow planning that is grounded in the relevant context and there are many aspects to memory that you should take\\nMemory in this context is a set of tool commands for updating a list that gets inserted into the system prompt across chat sessions. https://\\nIn summary, short-term memory is associated with working memory, while long-term memory encompasses episodic memory (experiences), semantic memory (knowledge), and procedural memory (skills and procedures) in AI agents. These memory components work together to enable the agent\\'s cognitive capabilities and performance across various tasks. [...] Reduction in redundancy: Memory systems help avoid redundant processing by recalling previously encountered information, thus improving response time and resource utilisation.\\nAdaptive interactions: AI can adapt to users\\' changing needs and preferences over time, offering more relevant and accurate responses. [...] Contextual awareness: Short-term memory bridges the gap between interactions, allowing agents to recall recent user inputs and tailor responses accordingly. This is akin to human working memory, where immediate past interactions inform the current response.\\nFacilitate long-term learning: Long-term memory stores past experiences, enabling agents to build knowledge and improve decision-making over time.')], 'question': \"What is the function of memory in an agent's system?\", 'generation': \"Memory in an agent's system serves the function of providing both short-term and long-term memory capabilities. Short-term memory allows the agent to learn in-context, while long-term memory enables the retention and recall of information over extended periods. Memory is essential for agents to adapt, learn from feedback, and improve their performance over time.\"}}\n",
            "--------------\n",
            "VALUE\n",
            "{'documents': [Document(metadata={'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.'), Document(metadata={'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.'), Document(metadata={}, page_content='Memory is a cognitive function that allows people to store, retrieve, and use information to understand their present and future. Consider the frustration of working with a colleague who forgets everything you tell them, requiring constant repetition! As AI agents undertake more complex tasks involving numerous user interactions, equipping them with memory becomes equally crucial for efficiency and user satisfaction. With memory, agents can learn from feedback and adapt to users\\' preferences. [...] | Procedural | Instructions | Instincts or motor skills | Agent system prompt |\\nSemantic Memory¶\\nSemantic memory, both in humans and AI agents, involves the retention of specific facts and concepts. In humans, it can include information learned in school and the understanding of concepts and their relationships. For AI agents, semantic memory is often used to personalize applications by remembering facts or concepts from past interactions. [...] When do you want to update memories?\\nMemory can be updated as part of an agent\\'s application logic (e.g. \"on the hot path\"). In this case, the agent typically decides to remember facts before responding to a user. Alternatively, memory can be updated as a background task (logic that runs in the background / asynchronously and generates memories). We explain the tradeoffs between these approaches in the section below.\\nMemory types¶\\nPractical: Memory underlies many of our cognitive functions. Far from being just a storage system for past events, memory actively helps us think about the future and make decisions. Drawing on past experiences lets us simulate possible future scenarios and apply lessons learned when facing choices. In fact, memory is involved in everything from problem-solving and communication to social skills like empathy - suggesting it\\'s woven into nearly every aspect of complex thought. Without memory, [...] Memory also enables meaningful personalization. When an AI agent remembers your preferences, history, or goals, it can tailor its responses specifically to you. A personal assistant that remembers your favorite restaurants or previous travel plans can make more relevant suggestions. A recommendation system that recalls your past ratings can better predict what you\\'ll like. In technical terms, long-term memory lets agents store historical data and user profiles, which directly improves their [...] Memory in AI doesn\\'t just produce better task performance – it shapes how users emotionally relate to and trust the system. An AI agent capable of remembering and learning over time tends to feel more human and empathetic.\\nMemory in agents is one of the main tools to allow planning that is grounded in the relevant context and there are many aspects to memory that you should take\\nMemory in this context is a set of tool commands for updating a list that gets inserted into the system prompt across chat sessions. https://\\nIn summary, short-term memory is associated with working memory, while long-term memory encompasses episodic memory (experiences), semantic memory (knowledge), and procedural memory (skills and procedures) in AI agents. These memory components work together to enable the agent\\'s cognitive capabilities and performance across various tasks. [...] Reduction in redundancy: Memory systems help avoid redundant processing by recalling previously encountered information, thus improving response time and resource utilisation.\\nAdaptive interactions: AI can adapt to users\\' changing needs and preferences over time, offering more relevant and accurate responses. [...] Contextual awareness: Short-term memory bridges the gap between interactions, allowing agents to recall recent user inputs and tailor responses accordingly. This is akin to human working memory, where immediate past interactions inform the current response.\\nFacilitate long-term learning: Long-term memory stores past experiences, enabling agents to build knowledge and improve decision-making over time.')], 'question': \"What is the function of memory in an agent's system?\", 'generation': \"Memory in an agent's system serves the function of providing both short-term and long-term memory capabilities. Short-term memory allows the agent to learn in-context, while long-term memory enables the retention and recall of information over extended periods. Memory is essential for agents to adapt, learn from feedback, and improve their performance over time.\"}\n",
            "--------------\n",
            "Assistant: Memory in an agent's system serves the function of providing both short-term and long-term memory capabilities. Short-term memory allows the agent to learn in-context, while long-term memory enables the retention and recall of information over extended periods. Memory is essential for agents to adapt, learn from feedback, and improve their performance over time.\n",
            "User: talk more about agent alignment\n",
            "---RETRIEVE---\n",
            "EVENT\n",
            "{'retrieve': {'documents': [Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en'}, page_content='}\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\", 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en'}, page_content=\"Nlp\\nLanguage-Model\\nAlignment\\nSteerability\\nPrompting\\n\\n\\n\\n« \\n\\nLLM Powered Autonomous Agents\\n\\n\\n »\\n\\nThe Transformer Family Version 2.0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n© 2025 Lil'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod\"), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en'}, page_content=\"Planning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X's plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\")], 'question': 'talk more about agent alignment'}}\n",
            "--------------\n",
            "VALUE\n",
            "{'documents': [Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en'}, page_content='}\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\", 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en'}, page_content=\"Nlp\\nLanguage-Model\\nAlignment\\nSteerability\\nPrompting\\n\\n\\n\\n« \\n\\nLLM Powered Autonomous Agents\\n\\n\\n »\\n\\nThe Transformer Family Version 2.0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n© 2025 Lil'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod\"), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en'}, page_content=\"Planning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X's plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\")], 'question': 'talk more about agent alignment'}\n",
            "--------------\n",
            "Assistant: No generation yet.\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
            "EVENT\n",
            "{'grade_documents': {'documents': [Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory')], 'question': 'talk more about agent alignment', 'web_search': 'Yes'}}\n",
            "--------------\n",
            "VALUE\n",
            "{'documents': [Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory')], 'question': 'talk more about agent alignment', 'web_search': 'Yes'}\n",
            "--------------\n",
            "Assistant: No generation yet.\n",
            "---TRANSFORM QUERY---\n",
            "EVENT\n",
            "{'transform_query': {'documents': [Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory')], 'question': 'What is the significance of agent alignment in the context of organizational success?'}}\n",
            "--------------\n",
            "VALUE\n",
            "{'documents': [Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory')], 'question': 'What is the significance of agent alignment in the context of organizational success?'}\n",
            "--------------\n",
            "Assistant: No generation yet.\n",
            "---WEB SEARCH---\n",
            "EVENT\n",
            "{'web_search_node': {'documents': [Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={}, page_content=\"In today's complex business environment, stakeholder alignment plays a crucial role in achieving organizational success. By understanding and addressing the needs and expectations of various stakeholders, companies can foster positive relationships, enhance performance, and drive strategic decision-making. This article explores the significance of stakeholder alignment, its impact on organizational success, key principles for effective alignment, overcoming challenges, and measuring success. [...] In conclusion, stakeholder alignment is vital for achieving organizational success. By understanding stakeholder needs and expectations, fostering positive relationships, and aligning interests with organizational goals, organizations can enhance performance, drive strategic decision-making, overcome challenges, and measure success. Stakeholder alignment is a dynamic process that requires ongoing efforts and continuous improvement. Embracing stakeholder alignment as a cornerstone of [...] Stakeholder alignment is vital for organizations as it helps create a unified vision and fosters a sense of ownership among stakeholders. When stakeholders are aligned, they are more likely to support the organization's strategies, initiatives, and decision-making processes. This alignment can lead to increased trust, collaboration, and ultimately, organizational success.\\nOrganizational alignment is crucial for the success and sustainability of any business, regardless of its size or industry. Without alignment,\\nWhat is organizational alignment?\\nOrganizational alignment is a business strategy that involves coordinating efforts, resources, and procedures toward a common goal. This entails achieving both horizontal and vertical alignment, where departments, teams, and individuals work together to achieve primary objectives.\\nWhy is organizational alignment important? [...] Achieving organizational alignment is essential for companies looking to ensure that business components work together toward common goals, where overarching visions and values are consistently prioritized. Strategic alignment creates an environment where synergistic efforts pull in the same direction, bringing cohesion at every level of the organization.\\nThe benefits of achieving organizational alignment [...] Given the importance of organizational alignment for your business, knowing how you can attain and maintain it — using, for example, an organizational alignment framework — is essential.\\nTo help you understand and facilitate organizational alignment across your business, this article covers:\\nOrganisational alignment is when an organisation's goals, strategies, structures and processes all work in harmony.\\nWith an aligned team, a business delivers better employee AND customer experiences. Below are some key benefits of organizational alignment.\")], 'question': 'What is the significance of agent alignment in the context of organizational success?'}}\n",
            "--------------\n",
            "VALUE\n",
            "{'documents': [Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={}, page_content=\"In today's complex business environment, stakeholder alignment plays a crucial role in achieving organizational success. By understanding and addressing the needs and expectations of various stakeholders, companies can foster positive relationships, enhance performance, and drive strategic decision-making. This article explores the significance of stakeholder alignment, its impact on organizational success, key principles for effective alignment, overcoming challenges, and measuring success. [...] In conclusion, stakeholder alignment is vital for achieving organizational success. By understanding stakeholder needs and expectations, fostering positive relationships, and aligning interests with organizational goals, organizations can enhance performance, drive strategic decision-making, overcome challenges, and measure success. Stakeholder alignment is a dynamic process that requires ongoing efforts and continuous improvement. Embracing stakeholder alignment as a cornerstone of [...] Stakeholder alignment is vital for organizations as it helps create a unified vision and fosters a sense of ownership among stakeholders. When stakeholders are aligned, they are more likely to support the organization's strategies, initiatives, and decision-making processes. This alignment can lead to increased trust, collaboration, and ultimately, organizational success.\\nOrganizational alignment is crucial for the success and sustainability of any business, regardless of its size or industry. Without alignment,\\nWhat is organizational alignment?\\nOrganizational alignment is a business strategy that involves coordinating efforts, resources, and procedures toward a common goal. This entails achieving both horizontal and vertical alignment, where departments, teams, and individuals work together to achieve primary objectives.\\nWhy is organizational alignment important? [...] Achieving organizational alignment is essential for companies looking to ensure that business components work together toward common goals, where overarching visions and values are consistently prioritized. Strategic alignment creates an environment where synergistic efforts pull in the same direction, bringing cohesion at every level of the organization.\\nThe benefits of achieving organizational alignment [...] Given the importance of organizational alignment for your business, knowing how you can attain and maintain it — using, for example, an organizational alignment framework — is essential.\\nTo help you understand and facilitate organizational alignment across your business, this article covers:\\nOrganisational alignment is when an organisation's goals, strategies, structures and processes all work in harmony.\\nWith an aligned team, a business delivers better employee AND customer experiences. Below are some key benefits of organizational alignment.\")], 'question': 'What is the significance of agent alignment in the context of organizational success?'}\n",
            "--------------\n",
            "Assistant: No generation yet.\n",
            "---GENERATE---\n",
            "EVENT\n",
            "{'generate': {'documents': [Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={}, page_content=\"In today's complex business environment, stakeholder alignment plays a crucial role in achieving organizational success. By understanding and addressing the needs and expectations of various stakeholders, companies can foster positive relationships, enhance performance, and drive strategic decision-making. This article explores the significance of stakeholder alignment, its impact on organizational success, key principles for effective alignment, overcoming challenges, and measuring success. [...] In conclusion, stakeholder alignment is vital for achieving organizational success. By understanding stakeholder needs and expectations, fostering positive relationships, and aligning interests with organizational goals, organizations can enhance performance, drive strategic decision-making, overcome challenges, and measure success. Stakeholder alignment is a dynamic process that requires ongoing efforts and continuous improvement. Embracing stakeholder alignment as a cornerstone of [...] Stakeholder alignment is vital for organizations as it helps create a unified vision and fosters a sense of ownership among stakeholders. When stakeholders are aligned, they are more likely to support the organization's strategies, initiatives, and decision-making processes. This alignment can lead to increased trust, collaboration, and ultimately, organizational success.\\nOrganizational alignment is crucial for the success and sustainability of any business, regardless of its size or industry. Without alignment,\\nWhat is organizational alignment?\\nOrganizational alignment is a business strategy that involves coordinating efforts, resources, and procedures toward a common goal. This entails achieving both horizontal and vertical alignment, where departments, teams, and individuals work together to achieve primary objectives.\\nWhy is organizational alignment important? [...] Achieving organizational alignment is essential for companies looking to ensure that business components work together toward common goals, where overarching visions and values are consistently prioritized. Strategic alignment creates an environment where synergistic efforts pull in the same direction, bringing cohesion at every level of the organization.\\nThe benefits of achieving organizational alignment [...] Given the importance of organizational alignment for your business, knowing how you can attain and maintain it — using, for example, an organizational alignment framework — is essential.\\nTo help you understand and facilitate organizational alignment across your business, this article covers:\\nOrganisational alignment is when an organisation's goals, strategies, structures and processes all work in harmony.\\nWith an aligned team, a business delivers better employee AND customer experiences. Below are some key benefits of organizational alignment.\")], 'question': 'What is the significance of agent alignment in the context of organizational success?', 'generation': \"Agent alignment in the context of organizational success refers to ensuring that the autonomous agents within a system are in sync with the organization's goals and strategies. By aligning agents with the company's objectives, they can efficiently handle complex tasks, reflect on past actions, and improve the quality of results. This alignment is crucial for enhancing performance, driving strategic decision-making, and ultimately contributing to organizational success.\"}}\n",
            "--------------\n",
            "VALUE\n",
            "{'documents': [Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={}, page_content=\"In today's complex business environment, stakeholder alignment plays a crucial role in achieving organizational success. By understanding and addressing the needs and expectations of various stakeholders, companies can foster positive relationships, enhance performance, and drive strategic decision-making. This article explores the significance of stakeholder alignment, its impact on organizational success, key principles for effective alignment, overcoming challenges, and measuring success. [...] In conclusion, stakeholder alignment is vital for achieving organizational success. By understanding stakeholder needs and expectations, fostering positive relationships, and aligning interests with organizational goals, organizations can enhance performance, drive strategic decision-making, overcome challenges, and measure success. Stakeholder alignment is a dynamic process that requires ongoing efforts and continuous improvement. Embracing stakeholder alignment as a cornerstone of [...] Stakeholder alignment is vital for organizations as it helps create a unified vision and fosters a sense of ownership among stakeholders. When stakeholders are aligned, they are more likely to support the organization's strategies, initiatives, and decision-making processes. This alignment can lead to increased trust, collaboration, and ultimately, organizational success.\\nOrganizational alignment is crucial for the success and sustainability of any business, regardless of its size or industry. Without alignment,\\nWhat is organizational alignment?\\nOrganizational alignment is a business strategy that involves coordinating efforts, resources, and procedures toward a common goal. This entails achieving both horizontal and vertical alignment, where departments, teams, and individuals work together to achieve primary objectives.\\nWhy is organizational alignment important? [...] Achieving organizational alignment is essential for companies looking to ensure that business components work together toward common goals, where overarching visions and values are consistently prioritized. Strategic alignment creates an environment where synergistic efforts pull in the same direction, bringing cohesion at every level of the organization.\\nThe benefits of achieving organizational alignment [...] Given the importance of organizational alignment for your business, knowing how you can attain and maintain it — using, for example, an organizational alignment framework — is essential.\\nTo help you understand and facilitate organizational alignment across your business, this article covers:\\nOrganisational alignment is when an organisation's goals, strategies, structures and processes all work in harmony.\\nWith an aligned team, a business delivers better employee AND customer experiences. Below are some key benefits of organizational alignment.\")], 'question': 'What is the significance of agent alignment in the context of organizational success?', 'generation': \"Agent alignment in the context of organizational success refers to ensuring that the autonomous agents within a system are in sync with the organization's goals and strategies. By aligning agents with the company's objectives, they can efficiently handle complex tasks, reflect on past actions, and improve the quality of results. This alignment is crucial for enhancing performance, driving strategic decision-making, and ultimately contributing to organizational success.\"}\n",
            "--------------\n",
            "Assistant: Agent alignment in the context of organizational success refers to ensuring that the autonomous agents within a system are in sync with the organization's goals and strategies. By aligning agents with the company's objectives, they can efficiently handle complex tasks, reflect on past actions, and improve the quality of results. This alignment is crucial for enhancing performance, driving strategic decision-making, and ultimately contributing to organizational success.\n",
            "User: What do you know about LangGraph?\n",
            "---RETRIEVE---\n",
            "EVENT\n",
            "{'retrieve': {'documents': [Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='[10] Karpas et al. “MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.” arXiv preprint arXiv:2205.00445 (2022).\\n[11] Nakano et al. “Webgpt: Browser-assisted question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. “TALM: Tool Augmented Language Models”\\n[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n[15] Li et al. “API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 (2023).'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={'title': \"Prompt Engineering | Lil'Log\", 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'language': 'en'}, page_content=\"Nlp\\nLanguage-Model\\nAlignment\\nSteerability\\nPrompting\\n\\n\\n\\n« \\n\\nLLM Powered Autonomous Agents\\n\\n\\n »\\n\\nThe Transformer Family Version 2.0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n© 2025 Lil'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod\"), Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en'}, page_content=\"Nlp\\nLanguage-Model\\nAgent\\nSteerability\\nPrompting\\n\\n\\n\\n« \\n\\nAdversarial Attacks on LLMs\\n\\n\\n »\\n\\nPrompt Engineering\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n© 2025 Lil'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod\")], 'question': 'What do you know about LangGraph?'}}\n",
            "--------------\n",
            "VALUE\n",
            "{'documents': [Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='[10] Karpas et al. “MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.” arXiv preprint arXiv:2205.00445 (2022).\\n[11] Nakano et al. “Webgpt: Browser-assisted question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. “TALM: Tool Augmented Language Models”\\n[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n[15] Li et al. “API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 (2023).'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={'title': \"Prompt Engineering | Lil'Log\", 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'language': 'en'}, page_content=\"Nlp\\nLanguage-Model\\nAlignment\\nSteerability\\nPrompting\\n\\n\\n\\n« \\n\\nLLM Powered Autonomous Agents\\n\\n\\n »\\n\\nThe Transformer Family Version 2.0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n© 2025 Lil'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod\"), Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en'}, page_content=\"Nlp\\nLanguage-Model\\nAgent\\nSteerability\\nPrompting\\n\\n\\n\\n« \\n\\nAdversarial Attacks on LLMs\\n\\n\\n »\\n\\nPrompt Engineering\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n© 2025 Lil'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod\")], 'question': 'What do you know about LangGraph?'}\n",
            "--------------\n",
            "Assistant: No generation yet.\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
            "EVENT\n",
            "{'grade_documents': {'documents': [], 'question': 'What do you know about LangGraph?', 'web_search': 'Yes'}}\n",
            "--------------\n",
            "VALUE\n",
            "{'documents': [], 'question': 'What do you know about LangGraph?', 'web_search': 'Yes'}\n",
            "--------------\n",
            "Assistant: No generation yet.\n",
            "---TRANSFORM QUERY---\n",
            "EVENT\n",
            "{'transform_query': {'documents': [], 'question': 'What are the key features and uses of LangGraph?'}}\n",
            "--------------\n",
            "VALUE\n",
            "{'documents': [], 'question': 'What are the key features and uses of LangGraph?'}\n",
            "--------------\n",
            "Assistant: No generation yet.\n",
            "---WEB SEARCH---\n",
            "EVENT\n",
            "{'web_search_node': {'documents': [Document(metadata={}, page_content='The main use is for adding cycles to your LLM application. Crucially, LangGraph is NOT optimized for acyclic, or Directed Acyclic Graph (DAG), workflows. If you want to build a DAG, you should just use LangChain Expression Language.\\nCycles are important for agent-like behaviours, where you call an LLM in a loop, asking it what action to take next.\\nSome key features of LangGraph include: [...] Listen\\nShare\\nLangGraph is a library for building stateful, multi-actor applications with LLMs. It extends the LangChain Expression Language with the ability to coordinate multiple chains (or actors) across multiple steps of computation in a cyclic manner. It is inspired by Pregel and Apache Beam. The current interface exposed is one inspired by NetworkX.\\nLangGraph is a new member of the LangChain ecosystem, providing a graph-based framework for building complex LLM applications. By organizing application logic into directed graphs, LangGraph makes constructing complex conversational flows more intuitive and flexible.\\nKey Features [...] Conclusion\\nLangGraph simplifies the development of complex LLM applications by providing intuitive graphical structures and state management mechanisms. It not only addresses the limitations of LCEL and AgentExecutor but also offers more powerful features and a better development experience.\\nKey features of LangChain include:\\n\\nLangGraph: orchestrating complex workflows\\n\\nLangGraph is built to handle more sophisticated and intricate workflows. While LangChain excels in straightforward task chaining, LangGraph takes it a step further by offering a graph-based approach to orchestrate complex conversational flows and data pipelines. This makes LangGraph particularly suitable for projects that require managing multiple agents, conditional logic, and stateful interactions. [...] LangGraph offers a set of features that make it easier to build and manage complex workflows with LLMs. In this section, we\\'ll see into some of its key capabilities, including cycles, branching, persistent state management, and human-in-the-loop workflows.Â\\n\\nCycles and branching [...] Key features of LangGraph include:\\n\\nKey Concepts of LangGraph\\n\\nUnderstanding LangGraph\\'s core concepts is essential to leveraging its full potential:\\n\\nCyclical graphs\\n\\nUnlike linear workflows, cyclical graphs allow for loops and repeated interactions. This is crucial for managing tasks that require multiple iterations or conditional branching based on dynamic inputs.\\n\\nNodes and edges\\nOne of LangGraph\\'s standout features is its automatic state management. This feature enables us to track and persist information across multiple interactions. As agents perform their tasks, the state is dynamically updated, ensuring the system maintains context and responds appropriately to new inputs.\\nCoordination [...] In educational platforms, LangGraph can be used to create adaptive learning environments that cater to individual learning styles and needs. Multiple agents can assess a student\\'s progress, provide customized exercises, and offer real-time feedback. The stateful nature of LangGraph ensures that the system retains information about each learner\\'s performance and preferences, enabling a more personalized and effective educational experience.\\nConclusion [...] For applications requiring autonomous decision-making, LangGraph enables the creation of agents that can perform tasks independently based on user inputs and predefined logic.\\nThese agents can execute complex workflows, interact with other systems, and adapt to new information dynamically. LangGraph\\'s structured framework ensures that each agent operates efficiently and effectively, making it suitable for tasks like automated customer support, data processing, and system monitoring.\\nLangGraph, as a powerful graph-structured programming tool, offers many advanced features to support the development of complex AI applications. This article delves into some key concepts and considerations of LangGraph to help developers better utilize this tool.\\n1. Data State and Induction Functions [...] By thoroughly understanding and rationally applying these features, developers can build more powerful, flexible, and efficient LangGraph applications. These advanced features of LangGraph provide strong support for the development of complex AI applications, but developers need to remain cautious and fully consider various situations when using them. As LangGraph continues to evolve and improve, we can expect it to bring more possibilities to AI application development in the future. [...] Nodes at the same level will execute in parallel, but the execution order is uncertain.\\nYou can control the execution flow by adjusting the way nodes are connected.\\n\\nFor example:\\ngraph.add_edge([\"left1\", \"right3\"], \"merge\")\\nThis allows the left1 and right3 nodes to be at the same level while connecting to the merge node.\\n3. CheckPoint Mechanism\\nCheckpoints can be seen as a storage medium for recording node states. Key features include:\\n\\nRetrieving the last state and history:')], 'question': 'What are the key features and uses of LangGraph?'}}\n",
            "--------------\n",
            "VALUE\n",
            "{'documents': [Document(metadata={}, page_content='The main use is for adding cycles to your LLM application. Crucially, LangGraph is NOT optimized for acyclic, or Directed Acyclic Graph (DAG), workflows. If you want to build a DAG, you should just use LangChain Expression Language.\\nCycles are important for agent-like behaviours, where you call an LLM in a loop, asking it what action to take next.\\nSome key features of LangGraph include: [...] Listen\\nShare\\nLangGraph is a library for building stateful, multi-actor applications with LLMs. It extends the LangChain Expression Language with the ability to coordinate multiple chains (or actors) across multiple steps of computation in a cyclic manner. It is inspired by Pregel and Apache Beam. The current interface exposed is one inspired by NetworkX.\\nLangGraph is a new member of the LangChain ecosystem, providing a graph-based framework for building complex LLM applications. By organizing application logic into directed graphs, LangGraph makes constructing complex conversational flows more intuitive and flexible.\\nKey Features [...] Conclusion\\nLangGraph simplifies the development of complex LLM applications by providing intuitive graphical structures and state management mechanisms. It not only addresses the limitations of LCEL and AgentExecutor but also offers more powerful features and a better development experience.\\nKey features of LangChain include:\\n\\nLangGraph: orchestrating complex workflows\\n\\nLangGraph is built to handle more sophisticated and intricate workflows. While LangChain excels in straightforward task chaining, LangGraph takes it a step further by offering a graph-based approach to orchestrate complex conversational flows and data pipelines. This makes LangGraph particularly suitable for projects that require managing multiple agents, conditional logic, and stateful interactions. [...] LangGraph offers a set of features that make it easier to build and manage complex workflows with LLMs. In this section, we\\'ll see into some of its key capabilities, including cycles, branching, persistent state management, and human-in-the-loop workflows.Â\\n\\nCycles and branching [...] Key features of LangGraph include:\\n\\nKey Concepts of LangGraph\\n\\nUnderstanding LangGraph\\'s core concepts is essential to leveraging its full potential:\\n\\nCyclical graphs\\n\\nUnlike linear workflows, cyclical graphs allow for loops and repeated interactions. This is crucial for managing tasks that require multiple iterations or conditional branching based on dynamic inputs.\\n\\nNodes and edges\\nOne of LangGraph\\'s standout features is its automatic state management. This feature enables us to track and persist information across multiple interactions. As agents perform their tasks, the state is dynamically updated, ensuring the system maintains context and responds appropriately to new inputs.\\nCoordination [...] In educational platforms, LangGraph can be used to create adaptive learning environments that cater to individual learning styles and needs. Multiple agents can assess a student\\'s progress, provide customized exercises, and offer real-time feedback. The stateful nature of LangGraph ensures that the system retains information about each learner\\'s performance and preferences, enabling a more personalized and effective educational experience.\\nConclusion [...] For applications requiring autonomous decision-making, LangGraph enables the creation of agents that can perform tasks independently based on user inputs and predefined logic.\\nThese agents can execute complex workflows, interact with other systems, and adapt to new information dynamically. LangGraph\\'s structured framework ensures that each agent operates efficiently and effectively, making it suitable for tasks like automated customer support, data processing, and system monitoring.\\nLangGraph, as a powerful graph-structured programming tool, offers many advanced features to support the development of complex AI applications. This article delves into some key concepts and considerations of LangGraph to help developers better utilize this tool.\\n1. Data State and Induction Functions [...] By thoroughly understanding and rationally applying these features, developers can build more powerful, flexible, and efficient LangGraph applications. These advanced features of LangGraph provide strong support for the development of complex AI applications, but developers need to remain cautious and fully consider various situations when using them. As LangGraph continues to evolve and improve, we can expect it to bring more possibilities to AI application development in the future. [...] Nodes at the same level will execute in parallel, but the execution order is uncertain.\\nYou can control the execution flow by adjusting the way nodes are connected.\\n\\nFor example:\\ngraph.add_edge([\"left1\", \"right3\"], \"merge\")\\nThis allows the left1 and right3 nodes to be at the same level while connecting to the merge node.\\n3. CheckPoint Mechanism\\nCheckpoints can be seen as a storage medium for recording node states. Key features include:\\n\\nRetrieving the last state and history:')], 'question': 'What are the key features and uses of LangGraph?'}\n",
            "--------------\n",
            "Assistant: No generation yet.\n",
            "---GENERATE---\n",
            "EVENT\n",
            "{'generate': {'documents': [Document(metadata={}, page_content='The main use is for adding cycles to your LLM application. Crucially, LangGraph is NOT optimized for acyclic, or Directed Acyclic Graph (DAG), workflows. If you want to build a DAG, you should just use LangChain Expression Language.\\nCycles are important for agent-like behaviours, where you call an LLM in a loop, asking it what action to take next.\\nSome key features of LangGraph include: [...] Listen\\nShare\\nLangGraph is a library for building stateful, multi-actor applications with LLMs. It extends the LangChain Expression Language with the ability to coordinate multiple chains (or actors) across multiple steps of computation in a cyclic manner. It is inspired by Pregel and Apache Beam. The current interface exposed is one inspired by NetworkX.\\nLangGraph is a new member of the LangChain ecosystem, providing a graph-based framework for building complex LLM applications. By organizing application logic into directed graphs, LangGraph makes constructing complex conversational flows more intuitive and flexible.\\nKey Features [...] Conclusion\\nLangGraph simplifies the development of complex LLM applications by providing intuitive graphical structures and state management mechanisms. It not only addresses the limitations of LCEL and AgentExecutor but also offers more powerful features and a better development experience.\\nKey features of LangChain include:\\n\\nLangGraph: orchestrating complex workflows\\n\\nLangGraph is built to handle more sophisticated and intricate workflows. While LangChain excels in straightforward task chaining, LangGraph takes it a step further by offering a graph-based approach to orchestrate complex conversational flows and data pipelines. This makes LangGraph particularly suitable for projects that require managing multiple agents, conditional logic, and stateful interactions. [...] LangGraph offers a set of features that make it easier to build and manage complex workflows with LLMs. In this section, we\\'ll see into some of its key capabilities, including cycles, branching, persistent state management, and human-in-the-loop workflows.Â\\n\\nCycles and branching [...] Key features of LangGraph include:\\n\\nKey Concepts of LangGraph\\n\\nUnderstanding LangGraph\\'s core concepts is essential to leveraging its full potential:\\n\\nCyclical graphs\\n\\nUnlike linear workflows, cyclical graphs allow for loops and repeated interactions. This is crucial for managing tasks that require multiple iterations or conditional branching based on dynamic inputs.\\n\\nNodes and edges\\nOne of LangGraph\\'s standout features is its automatic state management. This feature enables us to track and persist information across multiple interactions. As agents perform their tasks, the state is dynamically updated, ensuring the system maintains context and responds appropriately to new inputs.\\nCoordination [...] In educational platforms, LangGraph can be used to create adaptive learning environments that cater to individual learning styles and needs. Multiple agents can assess a student\\'s progress, provide customized exercises, and offer real-time feedback. The stateful nature of LangGraph ensures that the system retains information about each learner\\'s performance and preferences, enabling a more personalized and effective educational experience.\\nConclusion [...] For applications requiring autonomous decision-making, LangGraph enables the creation of agents that can perform tasks independently based on user inputs and predefined logic.\\nThese agents can execute complex workflows, interact with other systems, and adapt to new information dynamically. LangGraph\\'s structured framework ensures that each agent operates efficiently and effectively, making it suitable for tasks like automated customer support, data processing, and system monitoring.\\nLangGraph, as a powerful graph-structured programming tool, offers many advanced features to support the development of complex AI applications. This article delves into some key concepts and considerations of LangGraph to help developers better utilize this tool.\\n1. Data State and Induction Functions [...] By thoroughly understanding and rationally applying these features, developers can build more powerful, flexible, and efficient LangGraph applications. These advanced features of LangGraph provide strong support for the development of complex AI applications, but developers need to remain cautious and fully consider various situations when using them. As LangGraph continues to evolve and improve, we can expect it to bring more possibilities to AI application development in the future. [...] Nodes at the same level will execute in parallel, but the execution order is uncertain.\\nYou can control the execution flow by adjusting the way nodes are connected.\\n\\nFor example:\\ngraph.add_edge([\"left1\", \"right3\"], \"merge\")\\nThis allows the left1 and right3 nodes to be at the same level while connecting to the merge node.\\n3. CheckPoint Mechanism\\nCheckpoints can be seen as a storage medium for recording node states. Key features include:\\n\\nRetrieving the last state and history:')], 'question': 'What are the key features and uses of LangGraph?', 'generation': 'LangGraph is a library for building stateful, multi-actor applications with LLMs, allowing for the coordination of multiple chains in a cyclic manner. It simplifies the development of complex LLM applications by providing intuitive graphical structures and state management mechanisms. LangGraph is particularly suitable for projects that require managing multiple agents, conditional logic, and stateful interactions.'}}\n",
            "--------------\n",
            "VALUE\n",
            "{'documents': [Document(metadata={}, page_content='The main use is for adding cycles to your LLM application. Crucially, LangGraph is NOT optimized for acyclic, or Directed Acyclic Graph (DAG), workflows. If you want to build a DAG, you should just use LangChain Expression Language.\\nCycles are important for agent-like behaviours, where you call an LLM in a loop, asking it what action to take next.\\nSome key features of LangGraph include: [...] Listen\\nShare\\nLangGraph is a library for building stateful, multi-actor applications with LLMs. It extends the LangChain Expression Language with the ability to coordinate multiple chains (or actors) across multiple steps of computation in a cyclic manner. It is inspired by Pregel and Apache Beam. The current interface exposed is one inspired by NetworkX.\\nLangGraph is a new member of the LangChain ecosystem, providing a graph-based framework for building complex LLM applications. By organizing application logic into directed graphs, LangGraph makes constructing complex conversational flows more intuitive and flexible.\\nKey Features [...] Conclusion\\nLangGraph simplifies the development of complex LLM applications by providing intuitive graphical structures and state management mechanisms. It not only addresses the limitations of LCEL and AgentExecutor but also offers more powerful features and a better development experience.\\nKey features of LangChain include:\\n\\nLangGraph: orchestrating complex workflows\\n\\nLangGraph is built to handle more sophisticated and intricate workflows. While LangChain excels in straightforward task chaining, LangGraph takes it a step further by offering a graph-based approach to orchestrate complex conversational flows and data pipelines. This makes LangGraph particularly suitable for projects that require managing multiple agents, conditional logic, and stateful interactions. [...] LangGraph offers a set of features that make it easier to build and manage complex workflows with LLMs. In this section, we\\'ll see into some of its key capabilities, including cycles, branching, persistent state management, and human-in-the-loop workflows.Â\\n\\nCycles and branching [...] Key features of LangGraph include:\\n\\nKey Concepts of LangGraph\\n\\nUnderstanding LangGraph\\'s core concepts is essential to leveraging its full potential:\\n\\nCyclical graphs\\n\\nUnlike linear workflows, cyclical graphs allow for loops and repeated interactions. This is crucial for managing tasks that require multiple iterations or conditional branching based on dynamic inputs.\\n\\nNodes and edges\\nOne of LangGraph\\'s standout features is its automatic state management. This feature enables us to track and persist information across multiple interactions. As agents perform their tasks, the state is dynamically updated, ensuring the system maintains context and responds appropriately to new inputs.\\nCoordination [...] In educational platforms, LangGraph can be used to create adaptive learning environments that cater to individual learning styles and needs. Multiple agents can assess a student\\'s progress, provide customized exercises, and offer real-time feedback. The stateful nature of LangGraph ensures that the system retains information about each learner\\'s performance and preferences, enabling a more personalized and effective educational experience.\\nConclusion [...] For applications requiring autonomous decision-making, LangGraph enables the creation of agents that can perform tasks independently based on user inputs and predefined logic.\\nThese agents can execute complex workflows, interact with other systems, and adapt to new information dynamically. LangGraph\\'s structured framework ensures that each agent operates efficiently and effectively, making it suitable for tasks like automated customer support, data processing, and system monitoring.\\nLangGraph, as a powerful graph-structured programming tool, offers many advanced features to support the development of complex AI applications. This article delves into some key concepts and considerations of LangGraph to help developers better utilize this tool.\\n1. Data State and Induction Functions [...] By thoroughly understanding and rationally applying these features, developers can build more powerful, flexible, and efficient LangGraph applications. These advanced features of LangGraph provide strong support for the development of complex AI applications, but developers need to remain cautious and fully consider various situations when using them. As LangGraph continues to evolve and improve, we can expect it to bring more possibilities to AI application development in the future. [...] Nodes at the same level will execute in parallel, but the execution order is uncertain.\\nYou can control the execution flow by adjusting the way nodes are connected.\\n\\nFor example:\\ngraph.add_edge([\"left1\", \"right3\"], \"merge\")\\nThis allows the left1 and right3 nodes to be at the same level while connecting to the merge node.\\n3. CheckPoint Mechanism\\nCheckpoints can be seen as a storage medium for recording node states. Key features include:\\n\\nRetrieving the last state and history:')], 'question': 'What are the key features and uses of LangGraph?', 'generation': 'LangGraph is a library for building stateful, multi-actor applications with LLMs, allowing for the coordination of multiple chains in a cyclic manner. It simplifies the development of complex LLM applications by providing intuitive graphical structures and state management mechanisms. LangGraph is particularly suitable for projects that require managing multiple agents, conditional logic, and stateful interactions.'}\n",
            "--------------\n",
            "Assistant: LangGraph is a library for building stateful, multi-actor applications with LLMs, allowing for the coordination of multiple chains in a cyclic manner. It simplifies the development of complex LLM applications by providing intuitive graphical structures and state management mechanisms. LangGraph is particularly suitable for projects that require managing multiple agents, conditional logic, and stateful interactions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4tiFtX5Bp5KL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
